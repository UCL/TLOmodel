{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae826e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "import os\n",
    "os.chdir('C:/Users/sm2511/PycharmProjects/TLOmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9200b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Start 12:17\n"
     ]
    }
   ],
   "source": [
    "from scripts.consumable_resource_analyses.resource_functions import *\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import shapefile as shp\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# define a timestamp for script outputs\n",
    "timestamp = datetime.datetime.now().strftime(\"_%Y_%m_%d_%H_%M\")\n",
    "\n",
    "# print the start time of the script\n",
    "print('Script Start', datetime.datetime.now().strftime('%H:%M'))\n",
    "\n",
    "# define a pathway to the data folder (note: currently outside the TLO model directory)\n",
    "# remember to set working directory to TLOmodel/\n",
    "outputfilepath = Path(\"./outputs\")\n",
    "resourcefilepath = Path(\"./resources\")\n",
    "datafilepath = Path(\"./../../Documents/health_systems/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7625fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed data import\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# active analysis script\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#%% Data import and cleaning\n",
    "\n",
    "# importing 2018 LMIS data\n",
    "df_import = pd.read_csv(resourcefilepath / 'ResourceFile_LMIS_2018.csv', low_memory = False)\n",
    "#df_import = pd.read_csv('C:/Users/sm2511/PycharmProjects/TLOmodel/resources/ResourceFile_LMIS_2018.csv', low_memory=False)\n",
    "\n",
    "# importing facilities data\n",
    "master_facilities_df = pd.read_csv(resourcefilepath / 'ResourceFile_Master_Facilities_List.csv')\n",
    "master_facilities_df = master_facilities_df.drop(columns=['Unnamed: 0'])\n",
    "master_facilylist_df = pd.read_csv(resourcefilepath / 'ResourceFile_Facilities_For_Each_District.csv')\n",
    "\n",
    "# importing consumables list (consumables called upon by the disease modules)\n",
    "consumables_df = pd.read_csv(resourcefilepath / 'ResourceFile_Consumables_new.csv')\n",
    "consumables_df = consumables_df.drop(columns=['Unnamed: 0'])\n",
    "#consumables_df.columns = consumables_df.iloc[0]\n",
    "consumables_df = consumables_df.drop(consumables_df.index[0:4])\n",
    "consumables_df = consumables_df.reindex()\n",
    "consumables_df = consumables_df.dropna( how='any',\n",
    "                    subset=['Item_Code Description'])\n",
    "\n",
    "#nonalphanum_names = consumables_df[(consumables_df['Item_Code Used'] == \"78\")|(consumables_df['Item_Code Used'] == \"1902\")].index\n",
    "#consumables_df.drop(nonalphanum_names, inplace = True)\n",
    "\n",
    "consumables_df[\"Item_Code Description\"] = consumables_df[\"Item_Code Description\"].str.replace(\"\\'\", \"\").str.strip()\n",
    "print('Completed data import')\n",
    "\n",
    "# extract unique facilities and consumables from the resource files\n",
    "#facility_names_list = master_facilities_df['Facility Name'].unique()\n",
    "consumables_list = consumables_df['Item_Code Description_clean'].unique()\n",
    "df_resources_list = df_import['Fullproductname'].unique()\n",
    "df_facilities_list = df_import['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3047a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 unique resources in the LMIS database\n",
      " 212 unique resources in the consumables database\n"
     ]
    }
   ],
   "source": [
    "print(len(df_resources_list), \"unique resources in the LMIS database\\n\",\n",
    "     len(consumables_list), \"unique resources in the consumables database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdddeba",
   "metadata": {},
   "source": [
    "## Step 2 \n",
    "Match the names of resources in the Consumables database to the resource names in the LMIS dataset\n",
    "1. Try fuzzy matching using various matching mathods - simple ratio, partial ratio, token sort ratio, token set ratio\n",
    "2. Keep good matches from the fuzzy matching process (score > 90)\n",
    "3. Run manual checks on \"partial matches\" (score < 90)\n",
    "4. Manual matching for unmatched resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74f7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy matching consumable resources using simple ratio\n",
      "Fuzzy matching consumable resources using partial ratio\n",
      "Fuzzy matching consumable resources using token set ratio\n",
      "Fuzzy matching consumable resources using token sort ratio\n"
     ]
    }
   ],
   "source": [
    "# Fuzzy matching consumable resources, using various methods\n",
    "print('Fuzzy matching consumable resources using simple ratio')\n",
    "matches = fuzzy_finder_function(df_resources_list, consumables_list, fuzz.ratio)\n",
    "resource_matches = pd.DataFrame(matches, columns=['ResourceFile_Match', 'Confidence'])\n",
    "resource_matches['Fullproductname'] = df_resources_list\n",
    "resource_matches_simpr = resource_matches.reset_index(drop=True).sort_values(by='Confidence', ascending=False)\n",
    "\n",
    "print('Fuzzy matching consumable resources using partial ratio')\n",
    "matches = fuzzy_finder_function(df_resources_list, consumables_list, fuzz.partial_ratio)\n",
    "resource_matches = pd.DataFrame(matches, columns=['ResourceFile_Match', 'Confidence'])\n",
    "resource_matches['Fullproductname'] = df_resources_list\n",
    "resource_matches_pr = resource_matches.reset_index(drop=True).sort_values(by='Confidence', ascending=False)\n",
    "\n",
    "print('Fuzzy matching consumable resources using token set ratio')\n",
    "matches = fuzzy_finder_function(df_resources_list, consumables_list, fuzz.token_set_ratio)\n",
    "resource_matches = pd.DataFrame(matches, columns=['ResourceFile_Match', 'Confidence'])\n",
    "resource_matches['Fullproductname'] = df_resources_list\n",
    "resource_matches_tsetr = resource_matches.reset_index(drop=True).sort_values(by='Confidence', ascending=False)\n",
    "\n",
    "print('Fuzzy matching consumable resources using token sort ratio')\n",
    "matches = fuzzy_finder_function(df_resources_list, consumables_list, fuzz.token_sort_ratio)\n",
    "resource_matches = pd.DataFrame(matches, columns=['ResourceFile_Match', 'Confidence'])\n",
    "resource_matches['Fullproductname'] = df_resources_list\n",
    "resource_matches_tsortr = resource_matches.reset_index(drop=True).sort_values(by='Confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c3b071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 consumables matched out of  212 from 393  in the 2018 LMIS data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-071c79ef64b3>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resource_match_final['MatchingMethod'] = 'Simple Ratio'\n"
     ]
    }
   ],
   "source": [
    "# Iteratively append good matches to a dataframe\n",
    "# 1. Match based on simple ratio\n",
    "resource_match_finalsimp = resource_matches_simpr[resource_matches_simpr['Confidence'] > 90]\n",
    "resource_match_final = resource_match_finalsimp\n",
    "resource_match_final['MatchingMethod'] = 'Simple Ratio'\n",
    "\n",
    "# 2a. Match based on partial ratio\n",
    "resource_match_finalpr = resource_matches_pr[resource_matches_pr['Confidence'] > 90]\n",
    "\n",
    "# 2b. Append matches based on partial ratio to the final matched dataframe\n",
    "merge = pd.merge(resource_match_final, resource_match_finalpr, on = 'ResourceFile_Match', how='outer')\n",
    "resource_match_finalpr = merge.drop_duplicates()\n",
    "c1 = resource_match_finalpr['Confidence_x'] < 90\n",
    "c2 = resource_match_finalpr['Confidence_x'].notna()\n",
    "resource_match_finalpr = resource_match_finalpr[~c2]\n",
    "\n",
    "resource_match_finalpr = resource_match_finalpr.drop(['Confidence_x', 'Fullproductname_x'], axis=1)\n",
    "resource_match_finalpr =resource_match_finalpr.rename(columns={\"Confidence_y\":\"Confidence\", \"Fullproductname_y\": \"Fullproductname\"})\n",
    "resource_match_finalpr['MatchingMethod'] = 'Partial Ratio'\n",
    "resource_match_final = resource_match_final.append(resource_match_finalpr)\n",
    "\n",
    "# 3a. Match based on token sort ratio\n",
    "resource_match_finaltsortr = resource_matches_tsortr[resource_matches_tsortr['Confidence'] > 90]\n",
    "\n",
    "# 3b. Append matches based on token sort ratio to the final matched dataframe\n",
    "merge = pd.merge(resource_match_final, resource_match_finaltsortr, on = 'ResourceFile_Match', how='outer')\n",
    "resource_match_finaltsortr = merge.drop_duplicates()\n",
    "c1 = resource_match_finaltsortr['Confidence_x'] < 90\n",
    "c2 = resource_match_finaltsortr['Confidence_x'].notna()\n",
    "resource_match_finaltsortr = resource_match_finaltsortr[~c2]\n",
    "\n",
    "resource_match_finaltsortr = resource_match_finaltsortr.drop(['Confidence_x', 'Fullproductname_x'], axis=1)\n",
    "resource_match_finaltsortr =resource_match_finaltsortr.rename(columns={\"Confidence_y\":\"Confidence\", \"Fullproductname_y\": \"Fullproductname\"})\n",
    "resource_match_finaltsortr['MatchingMethod'] = 'Token Sort Ratio'\n",
    "resource_match_final = resource_match_final.append(resource_match_finaltsortr)\n",
    "\n",
    "# 4a. Match based on token set ratio\n",
    "resource_match_finaltsetr = resource_matches_tsetr[resource_matches_tsetr['Confidence'] > 90]\n",
    "\n",
    "# 4b. Append matches based on token set ratio to the final matched dataframe\n",
    "merge = pd.merge(resource_match_final, resource_match_finaltsetr, on = 'ResourceFile_Match', how='outer')\n",
    "resource_match_finaltsetr = merge.drop_duplicates()\n",
    "c1 = resource_match_finaltsetr['Confidence_x'] < 90\n",
    "c2 = resource_match_finaltsetr['Confidence_x'].notna()\n",
    "resource_match_finaltsetr = resource_match_finaltsetr[~c2]\n",
    "\n",
    "resource_match_finaltsetr = resource_match_finaltsetr.drop(['Confidence_x', 'Fullproductname_x'], axis=1)\n",
    "resource_match_finaltsetr =resource_match_finaltsetr.rename(columns={\"Confidence_y\":\"Confidence\", \"Fullproductname_y\": \"Fullproductname\"})\n",
    "resource_match_finaltsetr['MatchingMethod'] = 'Token Set Ratio'\n",
    "resource_match_final = resource_match_final.append(resource_match_finaltsetr)\n",
    "\n",
    "# Final checks and extract matched dataframe\n",
    "assert len(resource_match_final) == len(resource_match_finalpr) + len(resource_match_finalsimp) + len(resource_match_finaltsortr) +  + len(resource_match_finaltsetr)\n",
    "print(len(resource_match_final['ResourceFile_Match'].unique()), \"consumables matched out of \", len(consumables_list), \"from\", len(df_resources_list), \" in the 2018 LMIS data\")\n",
    "resource_match_final = resource_match_final.drop_duplicates(subset = ['ResourceFile_Match','Fullproductname'])\n",
    "resource_match_final.to_csv('C:/Users/sm2511/OneDrive - University of York/Documents/TLO-local/resource_match.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441bdf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two matched lists and extract into an excel file for manual manipulation\n",
    "resource_partmatch = resource_matches_simpr\n",
    "resource_partmatch['MatchingMethod'] = 'Simple Ratio'\n",
    "\n",
    "resource_partmatch = resource_partmatch.append(resource_matches_pr)\n",
    "c1 = resource_partmatch['MatchingMethod'].notna()\n",
    "resource_partmatch.loc[~c1, 'MatchingMethod'] = 'Partial Ratio'\n",
    "\n",
    "resource_partmatch = resource_partmatch.append(resource_matches_tsortr)\n",
    "c1 = resource_partmatch['MatchingMethod'].notna()\n",
    "resource_partmatch.loc[~c1, 'MatchingMethod'] = 'Token Sort Ratio'\n",
    "\n",
    "resource_partmatch = resource_partmatch.append(resource_matches_tsetr)\n",
    "c1 = resource_partmatch['MatchingMethod'].notna()\n",
    "resource_partmatch.loc[~c1, 'MatchingMethod'] = 'Token Set Ratio'\n",
    "\n",
    "resource_partmatch = resource_partmatch.dropna(how='all')\n",
    "resource_partmatch = resource_partmatch.drop_duplicates()\n",
    "\n",
    "resource_partmatch = pd.merge(resource_partmatch, resource_match_final, on = 'ResourceFile_Match', how = 'outer')\n",
    "c1 = resource_partmatch['Confidence_y'].notna()\n",
    "resource_partmatch = resource_partmatch[~c1]\n",
    "\n",
    "resource_partmatch = resource_partmatch.drop(['Confidence_y','Fullproductname_y','MatchingMethod_y'],axis = 1)\n",
    "resource_partmatch = resource_partmatch.rename(columns={\"Confidence_x\":\"Confidence\", \"Fullproductname_x\": \"Fullproductname\", \n",
    "                                                        \"MatchingMethod_x\":\"MatchingMethod\"})\n",
    "\n",
    "resource_partmatch = resource_partmatch.drop_duplicates(subset = ['ResourceFile_Match','Fullproductname'])\n",
    "\n",
    "resource_partmatch.to_csv('C:/Users/sm2511/OneDrive - University of York/Documents/TLO-local/resource_unmatched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumable_names_list = consumables_df['Items'].unique()\n",
    "consumable_names_list = pd.DataFrame(consumable_names_list, columns=['ResourceFile_Match'])\n",
    "resource_unmatched = pd.merge(consumable_names_list, resource_partmatch, on = 'ResourceFile_Match', how = 'outer')\n",
    "resource_unmatched = resource_unmatched.dropna(how='all')\n",
    "c1 = resource_unmatched['Fullproductname'].notna()\n",
    "resource_unmatched = resource_unmatched[~c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5607d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_consumables = resource_partmatch.append(resource_unmatched)\n",
    "all_consumables.to_csv('C:/Users/sm2511/OneDrive - University of York/Documents/TLO-local/resource_partmatched_and_unmatched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79318a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy match consumables names list with itself\n",
    "consumable_names_list = consumables_df['Items'].unique()\n",
    "print('Fuzzy matching consumable resources using partial ratio')\n",
    "matches = fuzzy_finder_function(consumable_names_list, consumable_names_list, fuzz.partial_ratio)\n",
    "consumables_cleaned = pd.DataFrame(matches, columns=['ResourceFile_Match', 'Confidence'])\n",
    "#resource_matches['Fullproductname'] = df_resources_list\n",
    "#resource_matches_simpr = resource_matches.reset_index(drop=True).sort_values(by='Confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy match consumables names list with itself\n",
    "consumable_names_list = consumables_df['Items'].unique()\n",
    "print('Fuzzy matching consumable resources using partial ratio')\n",
    "matches = fuzzy_finder_function(consumable_names_list, consumable_names_list, fuzz.partial_ratio)\n",
    "consumables_cleaned = pd.DataFrame(matches, columns=['ResourceFile_Match', 'Confidence'])\n",
    "#resource_matches['Fullproductname'] = df_resources_list\n",
    "#resource_matches_simpr = resource_matches.reset_index(drop=True).sort_values(by='Confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee9f132",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'consumable_names_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f7435ce9b580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconsumables_cleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'otherpossible_drugname'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsumable_names_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mconsumables_cleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsumables_cleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Confidence'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconsumables_cleaned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'consumable_names_list' is not defined"
     ]
    }
   ],
   "source": [
    "consumables_cleaned['otherpossible_drugname'] = consumable_names_list\n",
    "consumables_cleaned = consumables_cleaned.reset_index(drop=True).sort_values(by='Confidence', ascending=False)\n",
    "consumables_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c6723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
