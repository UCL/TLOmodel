{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From https://planetarycomputer.microsoft.com/dataset/cil-gdpcir-cc0#Ensemble-example",
   "id": "527d7ca56042f1c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T09:41:20.078055Z",
     "start_time": "2025-01-07T09:41:18.319974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import planetary_computer\n",
    "import pystac_client\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import difflib\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from carbonplan import styles  # noqa: F401\n",
    "import intake\n",
    "import cmip6_downscaling\n"
   ],
   "id": "7b5963dac1c0b629",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load and organise data",
   "id": "900df6fa0e1e8d25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T09:12:15.018110Z",
     "start_time": "2025-01-07T08:36:55.986715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pystac_client import Client\n",
    "from planetary_computer import sign_inplace\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Open the catalog\n",
    "catalog = Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1/\",\n",
    "    modifier=sign_inplace,\n",
    ")\n",
    "\n",
    "# Get the collections\n",
    "scenarios = [\"ssp585\"]  # Change as needed\n",
    "variable_id = \"pr\"  # Precipitation variable\n",
    "\n",
    "for scenario in scenarios:\n",
    "    search = catalog.search(\n",
    "        collections=[\"cil-gdpcir-cc0\", \"cil-gdpcir-cc-by\"],\n",
    "        query={\"cmip6:experiment_id\": {\"eq\": scenario}},\n",
    "    )\n",
    "    ensemble = search.item_collection()\n",
    "    print(f\"Number of items found: {len(ensemble)}\")\n",
    "\n",
    "    # Read and process each dataset\n",
    "    datasets_by_model = []\n",
    "    for item in tqdm(ensemble):\n",
    "        asset = item.assets[variable_id]\n",
    "        datasets_by_model.append(\n",
    "            xr.open_dataset(asset.href, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "        )\n",
    "\n",
    "    # Combine datasets by model\n",
    "    all_datasets = xr.concat(\n",
    "        datasets_by_model,\n",
    "        dim=pd.Index([ds.attrs[\"source_id\"] for ds in datasets_by_model], name=\"model\"),\n",
    "        combine_attrs=\"drop_conflicts\",\n",
    "    )\n",
    "\n",
    "    # Define the spatial and temporal bounds\n",
    "    lon_bounds = slice(32.67161823, 35.91841716)\n",
    "    lat_bounds = slice(-17.12627881, -9.36366167)\n",
    "    time_range = pd.date_range(\"2061-01-01\", \"2071-01-01\", freq=\"Y\")\n",
    "\n",
    "    # Process each year\n",
    "    output_dir = \"/Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL/\"\n",
    "    yearly_files = []\n",
    "    for year in time_range.year:\n",
    "        yearly_subset = all_datasets.pr.sel(\n",
    "            lon=lon_bounds,\n",
    "            lat=lat_bounds,\n",
    "            time=slice(f\"{year}-01-01\", f\"{year}-12-31\"),\n",
    "        )\n",
    "        yearly_file = f\"{output_dir}/CIL_subset_{scenario}_{year}.nc\"\n",
    "        yearly_subset.to_netcdf(yearly_file)\n",
    "        yearly_files.append(yearly_file)\n",
    "        print(f\"Saved yearly data for {year} to {yearly_file}\")\n",
    "\n",
    "    # Combine all yearly files into one NetCDF file\n",
    "    combined_output = f\"{output_dir}/CIL_subsetted_all_model_{scenario}.nc\"\n",
    "    combined_dataset = xr.open_mfdataset(yearly_files, combine=\"by_coords\")\n",
    "    combined_dataset.to_netcdf(combined_output)\n",
    "    print(f\"Saved combined dataset to {combined_output}\")"
   ],
   "id": "fc5f8a6d54c1a89d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items found: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 8/22 [00:37<01:31,  6.57s/it]Task exception was never retrieved\n",
      "future: <Task finished name='Task-60994' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-60998' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61006' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61020' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61009' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61016' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61017' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61019' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61010' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61018' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61014' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61011' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-61015' coro=<_AsyncChunkDownloader.process_chunk() done, defined at /opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py:75> exception=SocketTimeoutError('Timeout on reading data from socket')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 77, in process_chunk\n",
      "    chunk_data, _ = await self._download_chunk(chunk_start, chunk_end - 1)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 141, in _download_chunk\n",
      "    chunk_data = await process_content(response, offset[0], offset[1], self.encryption_options)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/storage/blob/aio/_download_async.py\", line 49, in process_content\n",
      "    await data.response.read()\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/azure/core/rest/_aiohttp.py\", line 215, in read\n",
      "    self._content = await self._internal_response.read()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/client_reqrep.py\", line 1214, in read\n",
      "    self._body = await self.content.read()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 415, in read\n",
      "    block = await self.readany()\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 437, in readany\n",
      "    await self._wait(\"readany\")\n",
      "  File \"/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/aiohttp/streams.py\", line 344, in _wait\n",
      "    await waiter\n",
      "aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket\n",
      "100%|██████████| 22/22 [02:45<00:00,  7.53s/it]\n",
      "/var/folders/1z/j8w4v5lj4k580xt42fkwh7dw0000gn/T/ipykernel_24684/2600312277.py:43: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  time_range = pd.date_range(\"2061-01-01\", \"2071-01-01\", freq=\"Y\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved yearly data for 2061 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2061.nc\n",
      "Saved yearly data for 2062 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2062.nc\n",
      "Saved yearly data for 2063 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2063.nc\n",
      "Saved yearly data for 2064 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2064.nc\n",
      "Saved yearly data for 2065 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2065.nc\n",
      "Saved yearly data for 2066 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2066.nc\n",
      "Saved yearly data for 2067 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2067.nc\n",
      "Saved yearly data for 2068 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2068.nc\n",
      "Saved yearly data for 2069 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2069.nc\n",
      "Saved yearly data for 2070 to /Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL//CIL_subset_ssp585_2070.nc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 62\u001B[0m\n\u001B[1;32m     60\u001B[0m combined_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/CIL_subsetted_all_model_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscenario\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.nc\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     61\u001B[0m combined_dataset \u001B[38;5;241m=\u001B[39m xr\u001B[38;5;241m.\u001B[39mopen_mfdataset(yearly_files, combine\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mby_coords\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 62\u001B[0m \u001B[43mcombined_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_netcdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcombined_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSaved combined dataset to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcombined_output\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/xarray/core/dataset.py:2372\u001B[0m, in \u001B[0;36mDataset.to_netcdf\u001B[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001B[0m\n\u001B[1;32m   2369\u001B[0m     encoding \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   2370\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxarray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackends\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_netcdf\n\u001B[0;32m-> 2372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_netcdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001B[39;49;00m\n\u001B[1;32m   2373\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2374\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2375\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2376\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2377\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2378\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2379\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2380\u001B[0m \u001B[43m    \u001B[49m\u001B[43munlimited_dims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munlimited_dims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2381\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2382\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmultifile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2383\u001B[0m \u001B[43m    \u001B[49m\u001B[43minvalid_netcdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minvalid_netcdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2384\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauto_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2385\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/xarray/backends/api.py:1882\u001B[0m, in \u001B[0;36mto_netcdf\u001B[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001B[0m\n\u001B[1;32m   1879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m multifile:\n\u001B[1;32m   1880\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m writer, store\n\u001B[0;32m-> 1882\u001B[0m writes \u001B[38;5;241m=\u001B[39m \u001B[43mwriter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcompute\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(target, BytesIO):\n\u001B[1;32m   1885\u001B[0m     store\u001B[38;5;241m.\u001B[39msync()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/xarray/backends/common.py:351\u001B[0m, in \u001B[0;36mArrayWriter.sync\u001B[0;34m(self, compute, chunkmanager_store_kwargs)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunkmanager_store_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    349\u001B[0m     chunkmanager_store_kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 351\u001B[0m delayed_store \u001B[38;5;241m=\u001B[39m \u001B[43mchunkmanager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstore\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflush\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mregions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mchunkmanager_store_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msources \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargets \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/xarray/namedarray/daskmanager.py:247\u001B[0m, in \u001B[0;36mDaskManager.store\u001B[0;34m(self, sources, targets, **kwargs)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstore\u001B[39m(\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    241\u001B[0m     sources: Any \u001B[38;5;241m|\u001B[39m Sequence[Any],\n\u001B[1;32m    242\u001B[0m     targets: Any,\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    244\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdask\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marray\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m store\n\u001B[0;32m--> 247\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mstore\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[43msources\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtargets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/dask/array/core.py:1245\u001B[0m, in \u001B[0;36mstore\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1243\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m compute:\n\u001B[1;32m   1244\u001B[0m     store_dsk \u001B[38;5;241m=\u001B[39m HighLevelGraph(layers, dependencies)\n\u001B[0;32m-> 1245\u001B[0m     \u001B[43mcompute_as_if_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mArray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore_dsk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1246\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1248\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/dask/base.py:397\u001B[0m, in \u001B[0;36mcompute_as_if_collection\u001B[0;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m schedule \u001B[38;5;241m=\u001B[39m get_scheduler(scheduler\u001B[38;5;241m=\u001B[39mscheduler, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcls\u001B[39m, get\u001B[38;5;241m=\u001B[39mget)\n\u001B[1;32m    396\u001B[0m dsk2 \u001B[38;5;241m=\u001B[39m optimization_function(\u001B[38;5;28mcls\u001B[39m)(dsk, keys, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdsk2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/dask/threaded.py:91\u001B[0m, in \u001B[0;36mget\u001B[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001B[0m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pool, multiprocessing\u001B[38;5;241m.\u001B[39mpool\u001B[38;5;241m.\u001B[39mPool):\n\u001B[1;32m     89\u001B[0m         pool \u001B[38;5;241m=\u001B[39m MultiprocessingPoolExecutor(pool)\n\u001B[0;32m---> 91\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mget_async\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_max_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdsk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[43m    \u001B[49m\u001B[43mget_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_thread_get_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpack_exception\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpack_exception\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;66;03m# Cleanup pools associated to dead threads\u001B[39;00m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pools_lock:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/dask/local.py:505\u001B[0m, in \u001B[0;36mget_async\u001B[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001B[0m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwaiting\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mready\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrunning\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    504\u001B[0m     fire_tasks(chunksize)\n\u001B[0;32m--> 505\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key, res_info, failed \u001B[38;5;129;01min\u001B[39;00m \u001B[43mqueue_get\u001B[49m\u001B[43m(\u001B[49m\u001B[43mqueue\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mresult():\n\u001B[1;32m    506\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m failed:\n\u001B[1;32m    507\u001B[0m             exc, tb \u001B[38;5;241m=\u001B[39m loads(res_info)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/dask/local.py:140\u001B[0m, in \u001B[0;36mqueue_get\u001B[0;34m(q)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mqueue_get\u001B[39m(q):\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/queue.py:171\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qsize():\n\u001B[0;32m--> 171\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be a non-negative number\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tlo/lib/python3.11/threading.py:327\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 327\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find lowest, median, and highest value model across all lat/long and across all time points",
   "id": "8564e555060bf10a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Combine with grids for facilities",
   "id": "63aeda9cecaef726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T09:41:43.642027Z",
     "start_time": "2025-01-07T09:41:43.455377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ANC = True\n",
    "Inpatient = False\n",
    "multiplier = 1 # no need for multiplier \n",
    "years = range(2025, 2071) # final date is 1st Jan 2100\n",
    "month_lengths = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31] * len(years)\n",
    "window_size = 5\n",
    "\n",
    "if ANC:\n",
    "    reporting_data = pd.read_csv(\n",
    "        \"/Users/rem76/Desktop/Climate_change_health/Data/monthly_reporting_ANC_by_smaller_facility_lm.csv\")\n",
    "elif Inpatient:\n",
    "    reporting_data = pd.read_csv(\n",
    "        \"/Users/rem76/Desktop/Climate_change_health/Data/monthly_reporting_Inpatient_by_smaller_facility_lm.csv\")\n",
    "general_facilities = gpd.read_file(\"/Users/rem76/Desktop/Climate_change_health/Data/facilities_with_districts.shp\")\n",
    "\n",
    "facilities_with_lat_long = pd.read_csv(\n",
    "    \"/Users/rem76/Desktop/Climate_change_health/Data/facilities_with_lat_long_region.csv\")"
   ],
   "id": "5fa6e3fa0dff003a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/j8w4v5lj4k580xt42fkwh7dw0000gn/T/ipykernel_51565/4112377517.py:16: DtypeWarning: Columns (58,59,105,127,136,142,149,150,258,285,296,319,344,345,360,393,394,427,428,437,449,450,452,453,461,462,478,479,489,490,492,493,494,497,498,499,500,501,502,503,572,580,585,586,587,588,591,592,593,594,607,608,609,610,619,620,621,622,626,634,872,887,967,978,1066,1510) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  facilities_with_lat_long = pd.read_csv(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T09:41:45.213570Z",
     "start_time": "2025-01-07T09:41:45.207554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def unzip_all_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Unzips all .zip files in the specified directory, extracting each into a separate folder.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The path to the folder containing the .zip files.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.zip'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            extract_dir = os.path.join(directory, filename[:-4])\n",
    "            os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(extract_dir)\n",
    "            except zipfile.BadZipFile:\n",
    "                print(f\"Skipped {filename}: not a valid zip file.\")\n",
    "\n",
    "def get_facility_lat_long(reporting_facility, facilities_df, cutoff=0.90, n_matches=3):\n",
    "    \"\"\"\n",
    "    Function to find the closest matching facility name and return its latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    - reporting_facility: The facility name for which latitude and longitude are needed.\n",
    "    - facilities_df : DataFrame containing facility names ('Fname') and their corresponding latitudes ('A109__Latitude') and longitudes ('A109__Longitude').\n",
    "    - cutoff: The minimum similarity score for a match. Default is 0.90.\n",
    "    - n_matches: The maximum number of matches to consider. Default is 3.\n",
    "\n",
    "    Returns: match_name, lat_for_facility, long_for_facility\n",
    "\n",
    "    \"\"\"\n",
    "    matching_facility_name = difflib.get_close_matches(reporting_facility, facilities_df['Fname'], n=n_matches,\n",
    "                                                       cutoff=cutoff)\n",
    "\n",
    "    if matching_facility_name:\n",
    "        match_name = matching_facility_name[0]  # Access the string directly\n",
    "        lat_for_facility = facilities_df.loc[facilities_df['Fname'] == match_name, \"A109__Latitude\"].iloc[0]\n",
    "        long_for_facility = facilities_df.loc[facilities_df['Fname'] == match_name, \"A109__Longitude\"].iloc[0]\n",
    "        return match_name, lat_for_facility, long_for_facility\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "def extract_nc_files_from_unzipped_folders(directory):\n",
    "    \"\"\"\n",
    "    Searches for .nc files in the specified directory and all its subfolders,\n",
    "    and copies them to the output directory, maintaining the folder structure.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The path to the folder containing the unzipped folders.\n",
    "    \"\"\"\n",
    "    output_directory = os.path.join(directory, 'nc_files')\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        # Skip the output directory to prevent recursive copying\n",
    "        if root == output_directory:\n",
    "            continue\n",
    "\n",
    "        for filename in files:\n",
    "            if filename.endswith('.nc'):\n",
    "                source_file_path = os.path.join(root, filename)\n",
    "                destination_file_path = os.path.join(output_directory, filename)\n",
    "\n",
    "                # Only copy if the file does not already exist in the output directory\n",
    "                if not os.path.exists(destination_file_path):\n",
    "                    shutil.copy2(source_file_path, output_directory)"
   ],
   "id": "a9a92aa8bbb6b45a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-07T10:13:26.237514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_dir = \"/Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL/\"\n",
    "nc_file_directory = os.path.join(base_dir, 'nc_files')\n",
    "# NB these are daily \n",
    "scenarios = [\"ssp245\", \"ssp585\"]  \n",
    "\n",
    "data_by_model_and_grid = {}\n",
    "for scenario in scenarios:\n",
    "    print(scenario)\n",
    "    scenario_directory = os.path.join(base_dir, scenario)\n",
    "\n",
    "    grid_centroids = {}\n",
    "    cumulative_sum_by_models = {}\n",
    "    file_path_downscaled = f\"/Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL/\"\n",
    "    output_file = f\"CIL_combined_{scenario}_2025_2070.nc\"\n",
    "    file_pattern = os.path.join(file_path_downscaled, \"CIL_subset_ssp245_*.nc\")\n",
    "    data_all_models = xr.open_mfdataset(file_pattern, combine='nested', concat_dim=\"time\")\n",
    "    data_all_models.compute()\n",
    "\n",
    "    data_all_models.to_netcdf(output_file)\n",
    "    #data_all_models = xr.open_dataset(file_path_downscaled)\n",
    "    \n",
    "    ## Get models of interest - min, med, max\n",
    "    # Assuming 'pr' is the variable representing precipitation in the dataset\n",
    "    pr_aggregated = data_all_models.mean(dim=[\"lat\", \"lon\", \"time\"], skipna=True)  # Work with the 'pr' DataArray \n",
    "\n",
    "    # Find the model with the lowest value\n",
    "    min_model_object = pr_aggregated['pr'].idxmin(dim=\"model\")\n",
    "    min_model = min_model_object.values.item()\n",
    "    # Find the model with the median value\n",
    "    sorted_models = pr_aggregated.sortby(\"model\")\n",
    "    n_models = len(pr_aggregated.model)\n",
    "    median_index = n_models // 2\n",
    "    median_model_object = sorted_models[\"model\"][median_index]\n",
    "    print(median_model_object)\n",
    "    median_model = median_model_object.values.item()\n",
    "    print(median_model)\n",
    "    # Find the model with the highest value\n",
    "    max_model_object = pr_aggregated['pr'].idxmax(dim=\"model\")\n",
    "    max_model = max_model_object.values.item()\n",
    "\n",
    "    models_of_interest = [min_model, median_model, max_model]\n",
    "    #models_of_interest = [median_model]\n",
    "\n",
    "    print(\"Models of interest\", models_of_interest)\n",
    "    # see which facilities have reporting data and data on latitude and longitude\n",
    "    weather_df_lowest_window = pd.DataFrame()\n",
    "    weather_df_median_window = pd.DataFrame()\n",
    "    weather_df_highest_window = pd.DataFrame()\n",
    "\n",
    "    weather_df_lowest_monthly = pd.DataFrame()\n",
    "    weather_df_median_monthly = pd.DataFrame()\n",
    "    weather_df_highest_monthly = pd.DataFrame()\n",
    "    for model in models_of_interest:\n",
    "        data_per_model = data_all_models.sel(model=model)\n",
    "        pr_data = data_per_model.variables['pr'][:]  # in kg m-2 s-1 = mm s-1 x 86400 to get to day\n",
    "        lat_data = data_per_model.variables['lat'][:]\n",
    "        lon_data = data_per_model.variables['lon'][:]\n",
    "        lon_grid, lat_grid = np.meshgrid(lon_data, lat_data)\n",
    "        centroids = np.column_stack((lat_grid.ravel(), lon_grid.ravel()))\n",
    "\n",
    "        # Store centroids\n",
    "        grid_centroids[model] = centroids\n",
    "        grid_dictionary = {}\n",
    "        grid = 0\n",
    "        for i in lat_data:\n",
    "            for j in lon_data:\n",
    "                precip_data_for_grid = data_per_model.sel(lat=i, lon=j, method=\"nearest\")  # across all time points\n",
    "                grid_dictionary[grid] = precip_data_for_grid.pr.data\n",
    "                grid += 1\n",
    "        data_by_model_and_grid[model] = grid_dictionary\n",
    "\n",
    "    for reporting_facility in reporting_data.columns:\n",
    "        print(reporting_facility)\n",
    "        grid_precipitation_for_facility = {}\n",
    "        match_name, lat_for_facility, long_for_facility = get_facility_lat_long(reporting_facility, facilities_with_lat_long)\n",
    "        if not np.isnan(long_for_facility) and not np.isnan(lat_for_facility):\n",
    "            facility_location = np.array([lat_for_facility, long_for_facility])\n",
    "            kd_trees_by_model = {}\n",
    "\n",
    "            # Loop over each model of interest\n",
    "            for model in models_of_interest:\n",
    "                centroids = grid_centroids[model]\n",
    "                kd_tree = KDTree(centroids)\n",
    "                distance, closest_grid_index = kd_tree.query(facility_location)\n",
    "                grid_precipitation_for_facility[model] = data_by_model_and_grid[model][closest_grid_index]\n",
    "\n",
    "                cumulative_sum_monthly = []\n",
    "                cumulative_sum_window = []\n",
    "\n",
    "                begin_day = 0\n",
    "                # Calculate monthly cumulative sums\n",
    "                for month_idx, month_length in enumerate(month_lengths):\n",
    "                    days_for_grid_monthly = grid_precipitation_for_facility[model][begin_day:begin_day + month_length]\n",
    "                    cumulative_sums_monthly = [\n",
    "                        sum(days_for_grid_monthly)\n",
    "                    ]\n",
    "                    max_cumulative_sums_monthly = max(cumulative_sums_monthly)\n",
    "                    cumulative_sum_monthly.append(max_cumulative_sums_monthly)\n",
    "                    begin_day += month_length\n",
    "\n",
    "                begin_day = 0\n",
    "                # Calculate windowed cumulative sums\n",
    "                for month_idx, month_length in enumerate(month_lengths):\n",
    "                    days_for_grid_window = grid_precipitation_for_facility[model][begin_day:begin_day + month_length]\n",
    "\n",
    "                    cumulative_sums_window = [\n",
    "                        sum(days_for_grid_window[day:day + window_size])\n",
    "                        for day in range(month_length - window_size + 1)\n",
    "                    ]\n",
    "\n",
    "                    max_cumulative_sums_window = max(cumulative_sums_window)\n",
    "                    cumulative_sum_window.append(max_cumulative_sums_window)\n",
    "                    begin_day += month_length\n",
    "\n",
    "                # Assign the calculated data to the correct dataframe based on the model\n",
    "                if model == min_model:\n",
    "                    weather_df_lowest_monthly[reporting_facility] = cumulative_sum_monthly\n",
    "                    weather_df_lowest_window[reporting_facility] = cumulative_sum_window\n",
    "                elif model == median_model:\n",
    "                    weather_df_median_monthly[reporting_facility] = cumulative_sum_monthly\n",
    "                    weather_df_median_window[reporting_facility] = cumulative_sum_window\n",
    "                elif model == max_model:\n",
    "                    weather_df_highest_monthly[reporting_facility] = cumulative_sum_monthly\n",
    "                    weather_df_highest_window[reporting_facility] = cumulative_sum_window\n",
    "\n",
    "    if ANC:\n",
    "            weather_df_lowest_window.to_csv(Path(scenario_directory) / f\"lowest_model_daily_prediction_weather_by_facility_KDBall_ANC_downscaled_CIL_{scenario}.csv\", index=False)\n",
    "            weather_df_median_window.to_csv(Path(scenario_directory) / f\"median_model_daily_prediction_weather_by_facility_KDBall_ANC_downscaled_CIL_{scenario}.csv\", index=False)\n",
    "            weather_df_highest_window.to_csv(Path(scenario_directory) / f\"highest_model_daily_prediction_weather_by_facility_KDBall_ANC_downscaled_CIL_{scenario}.csv\", index=False)\n",
    "\n",
    "            weather_df_lowest_monthly.to_csv(Path(scenario_directory) / f\"lowest_model_monthly_prediction_weather_by_facility_KDBall_ANC_downscaled_CIL_{scenario}.csv\", index=False)\n",
    "            weather_df_median_monthly.to_csv(Path(scenario_directory) / f\"median_model_monthly_prediction_weather_by_facility_KDBall_ANC_downscaled_CIL_{scenario}.csv\", index=False)\n",
    "            weather_df_highest_monthly.to_csv(Path(scenario_directory) / f\"highest_model_monthly_prediction_weather_by_facility_KDBall_ANC_downscaled_CIL_{scenario}.csv\", index=False)\n"
   ],
   "id": "8a6e7f822720bd39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp245\n",
      "<xarray.DataArray 'model' ()> Size: 64B\n",
      "array('GFDL-CM4', dtype='<U16')\n",
      "Coordinates:\n",
      "    model    <U16 64B 'GFDL-CM4'\n",
      "GFDL-CM4\n",
      "Models of interest ['HadGEM3-GC31-LL', 'GFDL-CM4', 'INM-CM5-0']\n",
      "date\n",
      "Akasale Pvt Clinic\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T10:16:03.168255Z",
     "start_time": "2025-01-06T10:16:01.594780Z"
    }
   },
   "cell_type": "code",
   "source": "data_all_models.mean(dim=[\"lat\", \"lon\", \"time\"], skipna=True) ",
   "id": "b49522beae4dffc8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset> Size: 2kB\n",
       "Dimensions:  (model: 22)\n",
       "Coordinates:\n",
       "  * model    (model) <U16 1kB 'NESM3' 'GFDL-ESM4' ... 'FGOALS-g3' 'BCC-CSM2-MR'\n",
       "Data variables:\n",
       "    pr       (model) float64 176B nan nan nan nan nan ... nan nan nan nan nan"
      ],
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 2kB\n",
       "Dimensions:  (model: 22)\n",
       "Coordinates:\n",
       "  * model    (model) &lt;U16 1kB &#x27;NESM3&#x27; &#x27;GFDL-ESM4&#x27; ... &#x27;FGOALS-g3&#x27; &#x27;BCC-CSM2-MR&#x27;\n",
       "Data variables:\n",
       "    pr       (model) float64 176B nan nan nan nan nan ... nan nan nan nan nan</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-0baa8e83-3183-4668-b646-42ade1570ae9' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-0baa8e83-3183-4668-b646-42ade1570ae9' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>model</span>: 22</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-dd4b8c80-692c-4e58-affb-c1cdc9640bda' class='xr-section-summary-in' type='checkbox'  checked><label for='section-dd4b8c80-692c-4e58-affb-c1cdc9640bda' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>model</span></div><div class='xr-var-dims'>(model)</div><div class='xr-var-dtype'>&lt;U16</div><div class='xr-var-preview xr-preview'>&#x27;NESM3&#x27; ... &#x27;BCC-CSM2-MR&#x27;</div><input id='attrs-ca32c914-88a7-4543-85e4-5379f65d81af' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ca32c914-88a7-4543-85e4-5379f65d81af' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d89ff049-fa1b-44b9-a574-1041c523aef7' class='xr-var-data-in' type='checkbox'><label for='data-d89ff049-fa1b-44b9-a574-1041c523aef7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;NESM3&#x27;, &#x27;GFDL-ESM4&#x27;, &#x27;GFDL-CM4&#x27;, &#x27;NorESM2-MM&#x27;, &#x27;NorESM2-LM&#x27;,\n",
       "       &#x27;MPI-ESM1-2-LR&#x27;, &#x27;UKESM1-0-LL&#x27;, &#x27;HadGEM3-GC31-LL&#x27;, &#x27;MIROC-ES2L&#x27;,\n",
       "       &#x27;MIROC6&#x27;, &#x27;INM-CM5-0&#x27;, &#x27;INM-CM4-8&#x27;, &#x27;EC-Earth3-Veg&#x27;, &#x27;EC-Earth3-Veg-LR&#x27;,\n",
       "       &#x27;EC-Earth3&#x27;, &#x27;EC-Earth3-CC&#x27;, &#x27;MPI-ESM1-2-HR&#x27;, &#x27;CMCC-ESM2&#x27;,\n",
       "       &#x27;CMCC-CM2-SR5&#x27;, &#x27;CanESM5&#x27;, &#x27;FGOALS-g3&#x27;, &#x27;BCC-CSM2-MR&#x27;], dtype=&#x27;&lt;U16&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-846ef2b9-5351-446d-ad75-b7ae92e81fd0' class='xr-section-summary-in' type='checkbox'  checked><label for='section-846ef2b9-5351-446d-ad75-b7ae92e81fd0' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>pr</span></div><div class='xr-var-dims'>(model)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-0158cb22-2430-4840-af45-ddf1a516186d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0158cb22-2430-4840-af45-ddf1a516186d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e361bcb6-aa38-43e8-83c8-16169b2b722d' class='xr-var-data-in' type='checkbox'><label for='data-e361bcb6-aa38-43e8-83c8-16169b2b722d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([       nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan, 3.44298548, 3.57538716,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-bc99e85b-946e-42de-ac87-db10063fdd65' class='xr-section-summary-in' type='checkbox'  ><label for='section-bc99e85b-946e-42de-ac87-db10063fdd65' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>model</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-0368d72e-e8be-4250-bb7b-eca34eb744f7' class='xr-index-data-in' type='checkbox'/><label for='index-0368d72e-e8be-4250-bb7b-eca34eb744f7' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;NESM3&#x27;, &#x27;GFDL-ESM4&#x27;, &#x27;GFDL-CM4&#x27;, &#x27;NorESM2-MM&#x27;, &#x27;NorESM2-LM&#x27;,\n",
       "       &#x27;MPI-ESM1-2-LR&#x27;, &#x27;UKESM1-0-LL&#x27;, &#x27;HadGEM3-GC31-LL&#x27;, &#x27;MIROC-ES2L&#x27;,\n",
       "       &#x27;MIROC6&#x27;, &#x27;INM-CM5-0&#x27;, &#x27;INM-CM4-8&#x27;, &#x27;EC-Earth3-Veg&#x27;, &#x27;EC-Earth3-Veg-LR&#x27;,\n",
       "       &#x27;EC-Earth3&#x27;, &#x27;EC-Earth3-CC&#x27;, &#x27;MPI-ESM1-2-HR&#x27;, &#x27;CMCC-ESM2&#x27;,\n",
       "       &#x27;CMCC-CM2-SR5&#x27;, &#x27;CanESM5&#x27;, &#x27;FGOALS-g3&#x27;, &#x27;BCC-CSM2-MR&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;model&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f3e5cbd9-b7c7-4d4f-adc6-5e03458c1a39' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-f3e5cbd9-b7c7-4d4f-adc6-5e03458c1a39' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d60f3606b689dd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
