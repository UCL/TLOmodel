# This script runs a regression analysis on the cleaned openlmis dataframe generated by clean_raw_lmis_data.py script

# 1. Load libraries #
#####################
install.packages("pacman")
pacman::p_load(magrittr, # for %>% to work
               dplyr,
               modeest,
               broom.mixed, # for tidy to work to generate conf int table

               #Excel packages
               readxl,
               writexl,
               readr,

               # Regression packages
               nlme, # random effects regression - lme
               lmerTest, # random effects regression - lmer
               ggfortify, # for diagnostic plots
               glmmTMB, # Multilevel regression model
               MASS, # to run stepAIC with BIC criterion
               fixest, # clustered standard errors

               # visualisation packages
               jtools, # for regression visualisations
               sjPlot, # for plot_model
               sjmisc, # for plot_model
               viridis,
               ggpubr,
               ggplot2,
               cowplot, # for plot_grid (combine multiple graphs)
               gridExtra, # for combining forest plots (text grob)
               grid,

               # packages for tables
               gtsummary, # to get p-values in summary tables
               huxtable,  # to export regression summary tables using export_summs
               margins, # to calculate average marginal effects from logistic regression results
               janitor, # for tabyl command - get summary of categorical variable
               aod, # wald.test

               MESS, # for model comparison
               car, # to run Wald tests on regression outputs (Anova function)
               effects, # to allow for type= "eff" in plot_model
               cvTools, # for k-fold cross validation
               fastDummies # to create dummies from categorical variable
               )

# Set paths to store outputs
path_to_local_repo <- "/Users/sm2511/PycharmProjects/TLOmodel/" # Change this if different user
path_to_data <- paste0(path_to_local_repo, "outputs/", "openlmis_data/")
dir.create(file.path(path_to_data, "regression_analysis"))

# Load data
df <- read.csv(paste0(path_to_data, "regression_subset_df.csv"))

#######################################################################
# 2. Set up Dataframe for Regression analysis
#######################################################################
# Drop items and facilities with too few facilities reporting/items reported respectively
df_not_na_by_fac <- df %>%
  group_by(fac_name) %>%
  summarise(available_count = sum(!is.na(available_prob))) %>%
  arrange(available_count)

df_not_na_by_item <- df %>%
  group_by(item_code) %>%
  summarise(available_count = sum(!is.na(available_prob))) %>%
  arrange(available_count)

# Make a list of items with less than 10% facilities reporting (these are the consumables relevant to higher level RMNCH services for which
# only 64 facilities submitted reports)
items_with_too_few_obs <- subset(df_not_na_by_item, df_not_na_by_item$available_count < 1000)['item_code']
items_with_too_few_obs <- as.list(items_with_too_few_obs)

# Make a list of facilities with less than 10% items reported
print(max(df_not_na_by_fac$available_count))
facs_with_too_few_obs <- subset(df_not_na_by_fac, df_not_na_by_fac$available_count <= 0.1*max(df_not_na_by_fac$available_count))['fac_name']
facs_with_too_few_obs <- as.list(facs_with_too_few_obs)

df_for_regs <- subset(df, !(fac_name %in% facs_with_too_few_obs$fac_name))
df_for_regs <- subset(df_for_regs, !(item_code %in% items_with_too_few_obs$item_code))

print(paste(length(facs_with_too_few_obs$fac_name), " facilities dropped."))
print(paste(length(items_with_too_few_obs$item_code), " items dropped."))

# Set up dataframe for facility and item random effects model
#------------------------------------------------------------
# Note that this is model 4 in the Lancet GH paper. We do not include models 1-3 because these are not used for analysis on the impact of consumable availability scenarios
# add variables for random effects regression (re_reg)
chosen_varlist_for_re_reg <- c("available_prob", "year", "category", "is_vital", "fac_level", "district", "item_code", "month", "fac_name")
df_for_re_reg <- df_for_regs[chosen_varlist_for_re_reg]
df_for_re_reg <- na.omit(df_for_re_reg)

# Sort by fac_code
df_for_re_reg_sorted <-  df_for_re_reg[order(df_for_re_reg$fac_name, df_for_re_reg$item_code),]
# Create an numeric value for fac_code (clustering variable)
df_for_re_reg_sorted$fac_id <- as.integer(factor(df_for_re_reg_sorted$fac_name,levels=unique(df_for_re_reg_sorted$fac_name)))
df_for_re_reg_sorted <- as.data.frame(df_for_re_reg_sorted)

# Clean columns for regression analysis
df_for_re_reg_sorted$item_code <- factor(df_for_re_reg_sorted$item_code)
df_for_re_reg_sorted$is_vital[df_for_re_reg_sorted$is_vital == ""] <- "False"
df_for_re_reg_sorted$fac_name <- factor(df_for_re_reg_sorted$fac_name)

df_for_re_reg_sorted_months_collapsed <- df_for_re_reg_sorted %>%
  group_by(across(c("year", "category", "is_vital", "fac_level", "district", "item_code", "fac_name"))) %>%
  summarise(mean_available_prob = mean(available_prob, na.rm = TRUE), .groups = 'drop')

df_for_re_reg_sorted_months_collapsed_without_2023 <- df_for_re_reg_sorted_months_collapsed %>% filter(year != 2023)

#######################################################################
# 3. Run Regression Model
#######################################################################
# Fixed effects model
#---------------------
model_fe_yearly_data <- glm(mean_available_prob ~ fac_level + district + category + is_vital + year +
                             item_code + year*category + year*fac_level + year*is_vital,
                           family = binomial(logit), #gaussian(link = "identity")
                           data = df_for_re_reg_sorted_months_collapsed)
summary(model_fe_yearly_data)


# # Note that the following code does not generate clustered standard errors due to perfect collinearity
# # Model with clustered standard errors
# #--------------------------------------------------------
# df_for_re_reg_sorted_months_collapsed$cluster_variable <-  paste(df_for_re_reg_sorted_months_collapsed$fac_name, df_for_re_reg_sorted_months_collapsed$item_code, sep = "_")
#
# model_cse_item_and_fac_yearly_data <- feglm(mean_available_prob ~ year + fac_level + district + category + is_vital +
#                                year*category + year*fac_level + year*is_vital + year*district | (item_code),  # Clustering by item_code and fac_name,
#                               family = binomial(link = "logit"),
#                               data = df_for_re_reg_sorted_months_collapsed)
# summary(model_cse_item_and_fac_yearly_data)
#
# # Model with clustered standard errors (without 2023 data)
# #--------------------------------------------------------
# model_cse_item_and_fac_without_2023_yearly_data <- feglm(mean_available_prob ~ year + fac_level + district + category + is_vital +
#                                year*category + year*fac_level + year*is_vital + year*district | (item_code),
#                            family = binomial(logit), #gaussian(link = "identity")
#                            data = df_for_re_reg_sorted_months_collapsed_without_2023)
# summary(model_cse_item_and_fac_without_2023_yearly_data)

# # Linear model with clustered standard errors
# #--------------------------------------------------------
# linmodel_cse_item_and_fac_yearly_data <- feols(mean_available_prob ~ year + fac_level + district + category + is_vital +
#                   year * category + year * fac_level + year * is_vital + year*district ,
#                   data = df_for_re_reg_sorted_months_collapsed,
#                   vcov = ~ item_code + fac_name)
# summary(linmodel_cse_item_and_fac_yearly_data)

# Random effects model
# Note that this model does not converge but seems fairly accurate which might be OK?
logit_model_re_item_yearly_data <- glmer(mean_available_prob ~ year + fac_level + category + is_vital +
                               year*category + year*fac_level + year*is_vital + (1|item_code),
                           family = binomial(logit),
                           data = df_for_re_reg_sorted_months_collapsed,
                           control = glmerControl(optimizer = "bobyqa",
                                                  optCtrl=list(maxfun=1e5),
                                                  calc.derivs = TRUE))

#check_optimizer <- allFit(model_cse_item_and_fac_yearly_data) # this shows that only bobyqa and one other optimizer works

#gam_model_re_item_yearly_data <- gam(mean_available_prob ~ year + fac_level + category + is_vital +
#                                     year*category + year*fac_level + year*is_vital + s(item_code, bs = "re"),
#                                     family = binomial(link = "logit"),
#                                     data = df_for_re_reg_sorted_months_collapsed,
#                                     method = "REML")

#linear_model_re_item_and_fac_yearly_data <-  lmer(mean_available_prob ~ year + fac_level + category + is_vital +
#                               year*category + year*fac_level + year*is_vital +
#                             (1|district/fac_name) + (1|item_code),
#                           data = df_for_re_reg_sorted_months_collapsed)

# Save chosen regression results
#--------------------------------------
save(logit_model_re_item_yearly_data, file = paste0(path_to_data, "regression_analysis/logit_model_re_item_yearly_data.rdta"))

# Extract results to excel file
logit_model <- tidy(model_cse_item_and_fac_yearly_data, conf.int = TRUE)
write.csv(logit_model, file = paste0(path_to_data, "regression_analysis/logit_regression_model.csv"))
logit_model$estimate <- exp(logit_model$estimate)
logit_model$conf.low <- exp(logit_model$conf.low)
logit_model$conf.high <- exp(logit_model$conf.high)
write.csv(logit_model, file = paste0(path_to_data, "regression_analysis/logit_regression_model_exponentiated.csv"))

# Plot regression results
#---------------------------------------
varlist_margins <- c('fac_level', 'category', 'is_vital', 'year')
chosen_model <- logit_model_re_item_yearly_data

# All effects
#library(effects)
#all_effects <- allEffects(chosen_model)
#plot(all_effects)
#Effect("year", chosen_model)

library(broom.helpers)
table <- chosen_model %>%
  tbl_regression(
    tidy_fun = tidy_all_effects,
    estimate_fun = scales::label_percent(accuracy = .1)
  ) %>%
  bold_labels()
# Convert gtsummary table to a tibble (data frame)
marginal_predictions <- as_tibble(table)
# Save the data frame as a CSV file
write.csv(marginal_predictions, file = paste0(path_to_data, "regression_analysis/logit_model_re_item_yearly_data_marginal_predictions.csv"), row.names = FALSE)

# Line plots
png(paste0(path_to_data, "regression_analysis/predicted_values_by_fac_level.png"), width = 800, height = 600)
plot_model(chosen_model, type = "pred", terms = c( "year", "fac_level"))
dev.off()
png(paste0(path_to_data, "regression_analysis/predicted_values_by_eml_category.png"), width = 800, height = 600)
plot_model(chosen_model, type = "pred", terms = c( "year", "is_vital"))
dev.off()
png(paste0(path_to_data, "regression_analysis/predicted_values_by_programmatic_category.png"), width = 800, height = 600)
plot_model(chosen_model, type = "pred", terms = c( "year", "category"))
dev.off()
png(paste0(path_to_data, "regression_analysis/predicted_values_by_programmatic_category_static.png"), width = 800, height = 600)
plot_model(chosen_model, type = "pred", terms = c("category"))
dev.off()

#######################################################################
# 4. Extract average marginal effects for model
#######################################################################
# Based on the chosen regression models, predict the probability of consumable availability
explanatory_df <- df_for_re_reg_sorted_months_collapsed

# Create a dataframe with all combinations of factors
# Extract unique values from the dataframe
unique_item_codes <- unique(df_for_re_reg_sorted_months_collapsed$item_code)
unique_fac_levels <- unique(df_for_re_reg_sorted_months_collapsed$fac_level)
unique_is_vital <- unique(df_for_re_reg_sorted_months_collapsed$is_vital)
unique_categories <- unique(df_for_re_reg_sorted_months_collapsed$category)

# Create a dataframe with all combinations of the unique values for years 2019 and 2020
all_combinations <- expand.grid(
  item_code = unique_item_codes,
  fac_level = unique_fac_levels,
  is_vital = unique_is_vital,
  category = unique_categories,
  year = c(2018, 2019, 2020, 2021, 2022, 2023)  # Directly include the years as specified
)

# Predict availability for all possible combinations
predicted_availability <- predict(chosen_model,
                        all_combinations,
                        type = "response")

# plot predicted values versus actual values
#ggplot(predicted_availability, aes(x = mean_available_prob, y = predicted_availability)) +
#  geom_point() +  # Plot the points
#    geom_smooth(method = "lm", color = "blue", se = TRUE) +
#  labs(x = "Actual values", y = "Predicted values", title = "Scatter Plot of predicted and actual values of the probability of availability") +
#  theme_minimal()  +  # Use a minimal theme for a clean look
#  scale_x_continuous(limits = c(0, 1)) +
#      scale_y_continuous(limits = c(0, 1))

# Calculating the average of Col3 grouped by Col1 and Col2
average_effects <- predicted_availability %>%
  group_by(year, category, fac_level, is_vital) %>%
  summarise(average_predicted_availability = mean(predicted_availability), .groups = "drop")
write.csv(average_effects, file = paste0(path_to_data, "regression_analysis/average_effects_logit_model.csv"))

predicted_availability$deviation <- (predicted_availability$mean_available_prob - predicted_availability$predicted_availability)/predicted_availability$mean_available_prob * 100
ggplot(predicted_availability, aes(x = mean_available_prob, y= deviation)) + geom_point() + theme_minimal() + scale_y_continuous(limits = c(-100,100))

# Run a k-fold accurancy test to test the model
# This has been commented out because it can take a long time to run
# k_fold_cv_feglm <- function(data, k, formula) {
#   set.seed(123)  # For reproducibility
#   folds <- sample(rep(1:k, length.out = nrow(data)))
#   acc <- numeric(k)  # To store accuracy for each fold
#
#   for (i in 1:k) {
#     # Split the data into training and test sets
#     training <- data[folds != i, ]
#     test <- data[folds == i, ]
#
#     # Fit the model on the training data
#     model <- feglm(formula, family = binomial(link = "logit"),
#                               data = training)
#
#     # Predict on the test data
#     # Assuming a binary outcome and using a probability threshold of 0.5
#     prob_predictions <- predict(model, newdata = test, type = "response")
#     predictions <- ifelse(prob_predictions > 0.5, 1, 0)
#
#     # Calculate accuracy
#     actual <- ifelse(test[, 'mean_available_prob'] > 0.5, 1, 0)
#     acc[i] <- mean(predictions == actual)
#   }
#
#   return(list(Accuracy = acc, Mean_Accuracy = mean(acc)))
# }
# accuracy <- k_fold_cv_feglm(data = df_for_re_reg_sorted_months_collapsed, k = 2, formula = formula(chosen_model))
