{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:24:39.045549Z",
     "start_time": "2025-12-01T14:24:39.038923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tlo import Date\n",
    "from tlo.analysis.utils import (\n",
    "    extract_results,\n",
    "    summarize,\n",
    ")\n",
    "import geopandas as gpd"
   ],
   "id": "80975d6f4d215b92",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:24:39.089854Z",
     "start_time": "2025-12-01T14:24:39.086884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_folder = Path('/Users/rem76/PycharmProjects/TLOmodel/outputs/rm916@ic.ac.uk/climate_scenario_runs-2025-11-17T080947Z_mode_2_ssp_585')\n",
    "\n",
    "output_folder = Path('/Users/rem76/PycharmProjects/TLOmodel/outputs/rm916@ic.ac.uk/climate_scenario_runs-2025-11-17T080947Z_mode_2_ssp_585')"
   ],
   "id": "3ce5e78369a148d7",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:24:39.108602Z",
     "start_time": "2025-12-01T14:24:39.103478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "climate_sensitivity_analysis = False\n",
    "parameter_sensitivity_analysis = False\n",
    "main_text = False\n",
    "mode_2 = True\n",
    "\n",
    "scenario_names_all = [\"baseline\", \"ssp126_highest\", \"ssp126_lowest\", \"ssp126_mean\", \"ssp245_highest\", \"ssp245_lowest\", \"ssp245_mean\",  \"ssp585_highest\", \"ssp585_lowest\", \"ssp585_mean\"]\n",
    "\n",
    "if climate_sensitivity_analysis:\n",
    "\n",
    "    suffix = \"climate_SA\"\n",
    "    scenarios_of_interest = range(len(scenario_names_all))\n",
    "    scenario_names = scenario_names_all\n",
    "if parameter_sensitivity_analysis:\n",
    "    scenario_names = range(0, 9, 1)\n",
    "    scenarios_of_interest = scenario_names\n",
    "\n",
    "    suffix = \"parameter_SA\"\n",
    "if main_text:\n",
    "    scenario_names = [\n",
    "        \"Baseline\",\n",
    "        \"SSP 2.45 Mean\",\n",
    "    ]\n",
    "    suffix = \"main_text\"\n",
    "    scenarios_of_interest = [0, 6]\n",
    "\n",
    "if mode_2:\n",
    "    scenario_names = [\n",
    "        \"Baseline\",\n",
    "        \"SSP 5.85 Mean\",\n",
    "    ]\n",
    "    suffix = \"mode_2\"\n",
    "    scenarios_of_interest = [0, 1]"
   ],
   "id": "6558d5cd3b8e437e",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:24:39.113280Z",
     "start_time": "2025-12-01T14:24:39.109854Z"
    }
   },
   "cell_type": "code",
   "source": "scenario_names",
   "id": "50eaf6b5eb29c2ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baseline', 'SSP 5.85 Mean']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:24:39.116754Z",
     "start_time": "2025-12-01T14:24:39.113836Z"
    }
   },
   "cell_type": "code",
   "source": "mode_2",
   "id": "5ef604f458e89a41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:24:39.129969Z",
     "start_time": "2025-12-01T14:24:39.125903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "min_year = 2025\n",
    "max_year = 2027\n",
    "spacing_of_years = 1\n",
    "PREFIX_ON_FILENAME = '1'\n",
    "\n",
    "scenario_names_all = [\"baseline\", \"ssp126_highest\", \"ssp126_lowest\", \"ssp126_mean\", \"ssp245_highest\", \"ssp245_lowest\", \"ssp245_mean\",  \"ssp585_highest\", \"ssp585_lowest\", \"ssp585_mean\"]\n",
    "\n",
    "scenario_colours = ['#0081a7', '#00afb9', '#FEB95F', '#fed9b7', '#f07167']*4\n",
    "\n",
    "\n",
    "vmin = 0.5e+06\n",
    "vmax = 2.4e+06\n"
   ],
   "id": "e98fe5463e2f6a51",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Helper functions",
   "id": "46e1078b9fbf03a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:24:39.149432Z",
     "start_time": "2025-12-01T14:24:39.140245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_year_sequence = range(min_year, max_year, spacing_of_years)\n",
    "\n",
    "def get_num_treatments_total(_df):\n",
    "        _df['date'] = pd.to_datetime(_df['date'])\n",
    "\n",
    "        # filter to target period\n",
    "        _df = _df.loc[_df['date'].between(*TARGET_PERIOD)]\n",
    "        total = {}\n",
    "\n",
    "        for d in _df['hsi_event_key_to_counts']:\n",
    "            for k, v in d.items():\n",
    "                total[k] = 0\n",
    "                total[k] += total.get(k, 0) + v\n",
    "        return pd.Series(sum(total.values()), name=\"total_treatments\")\n",
    "\n",
    "def get_num_treatments_never_ran(_df):\n",
    "        _df['date'] = pd.to_datetime(_df['date'])\n",
    "\n",
    "        # filter to target period\n",
    "        _df = _df.loc[_df['date'].between(*TARGET_PERIOD)]\n",
    "        total = {}\n",
    "\n",
    "        for d in _df['never_ran_hsi_event_key_to_counts']:\n",
    "            for k, v in d.items():\n",
    "                total[k] = 0\n",
    "                total[k] += total.get(k, 0) + v\n",
    "        return pd.Series(sum(total.values()), name=\"total_treatments\")\n",
    "\n",
    "\n",
    "def get_num_treatments_total_delayed(_df):\n",
    "        _df['date'] = pd.to_datetime(_df['date'])\n",
    "\n",
    "        # filter to target period\n",
    "        _df = _df.loc[_df['date'].between(*TARGET_PERIOD)]\n",
    "        total = {}\n",
    "\n",
    "        for d in _df['weather_delayed_hsi_event_key_to_counts']:\n",
    "            for k, v in d.items():\n",
    "                total[k] = 0\n",
    "                total[k] += total.get(k, 0) + v\n",
    "        return pd.Series(sum(total.values()), name=\"total_treatments\")\n",
    "\n",
    "def get_num_treatments_total_cancelled(_df):\n",
    "        _df['date'] = pd.to_datetime(_df['date'])\n",
    "\n",
    "        # filter to target period\n",
    "        _df = _df.loc[_df['date'].between(*TARGET_PERIOD)]\n",
    "        total = {}\n",
    "\n",
    "        for d in _df['weather_cancelled_hsi_event_key_to_counts']:\n",
    "            for k, v in d.items():\n",
    "                total[k] = 0\n",
    "                total[k] += total.get(k, 0) + v\n",
    "        return pd.Series(sum(total.values()), name=\"total_treatments\")\n",
    "\n",
    "def get_population_for_year(_df):\n",
    "        \"\"\"Returns the population in the year of interest\"\"\"\n",
    "        _df['date'] = pd.to_datetime(_df['date'])\n",
    "        filtered_df = _df.loc[_df['date'].between(*TARGET_PERIOD)]\n",
    "        numeric_df = filtered_df.drop(columns=['female', 'male'], errors='ignore')\n",
    "        population_sum = numeric_df.sum(numeric_only=True)\n",
    "        return population_sum\n",
    "\n",
    "def get_num_dalys_by_cause_label(_df):\n",
    "        \"\"\"Return total number of DALYS (Stacked) by label (total by age-group within the TARGET_PERIOD)\"\"\"\n",
    "        return (\n",
    "            _df.loc[_df.year.between(*[i.year for i in TARGET_PERIOD])]\n",
    "            .drop(columns=[\"date\", \"sex\", \"age_range\", \"year\"])\n",
    "            .sum()\n",
    "        )\n",
    "\n"
   ],
   "id": "b02fbf296c22e448",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:28:57.042230Z",
     "start_time": "2025-12-01T14:24:39.153046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# We need to store delayed and cancelled data separately in the main loop\n",
    "# Add these dictionaries after all_scenarios_appointment_difference_*\n",
    "all_scenarios_appointment_delayed_mean = {}\n",
    "all_scenarios_appointment_cancelled_mean = {}\n",
    "all_scenarios_dalys_mean = {}\n",
    "\n",
    "# Then in your main loop (for draw in range(len(scenario_names))),\n",
    "# add this after calculating the difference:\n",
    "for draw in range(len(scenario_names)):\n",
    "    \n",
    "    all_years_data_delayed_mean = {}\n",
    "    all_years_data_cancelled_mean = {}\n",
    "    all_years_dalys_mean = {}\n",
    "\n",
    "    for target_year in target_year_sequence:\n",
    "        TARGET_PERIOD = (Date(target_year, 1, 1), Date(target_year, 12, 31))\n",
    "        \n",
    "        if draw == 0:\n",
    "            all_years_data_delayed_mean[target_year] = pd.Series([0], name='mean')\n",
    "            all_years_data_cancelled_mean[target_year] = pd.Series([0], name='mean')\n",
    "        else:\n",
    "            # Calculate proportions separately\n",
    "            num_delayed = summarize(extract_results(\n",
    "                results_folder,\n",
    "                module='tlo.methods.healthsystem.summary',\n",
    "                key='weather_delayed_hsi_event_counts',\n",
    "                custom_generate_series=get_num_treatments_total_delayed,\n",
    "                do_scaling=True\n",
    "            ), only_mean=False, collapse_columns=True)[draw]\n",
    "            \n",
    "            num_cancelled = summarize(extract_results(\n",
    "                results_folder,\n",
    "                module='tlo.methods.healthsystem.summary',\n",
    "                key='weather_cancelled_hsi_event_counts',\n",
    "                custom_generate_series=get_num_treatments_total_cancelled,\n",
    "                do_scaling=True\n",
    "            ), only_mean=False, collapse_columns=True)[draw]\n",
    "            \n",
    "            num_total = summarize(extract_results(\n",
    "                results_folder,\n",
    "                module='tlo.methods.healthsystem.summary',\n",
    "                key='hsi_event_counts',\n",
    "                custom_generate_series=get_num_treatments_total,\n",
    "                do_scaling=True\n",
    "            ), only_mean=False, collapse_columns=True)[draw]\n",
    "            \n",
    "            num_dalys = summarize(extract_results(\n",
    "                results_folder,\n",
    "                module='tlo.methods.healthburden',\n",
    "                key='dalys_stacked',\n",
    "                custom_generate_series=get_num_dalys_by_cause_label,\n",
    "                do_scaling=True\n",
    "            ), only_mean=False, collapse_columns=True)[draw]\n",
    "            print(num_dalys['mean'].sum())\n",
    "            \n",
    "            all_years_data_delayed_mean[target_year] = num_delayed['mean'] / num_total['mean']\n",
    "            all_years_data_cancelled_mean[target_year] = num_cancelled['mean'] / num_total['mean']\n",
    "            all_years_dalys_mean[target_year] = num_dalys['mean'].sum()\n",
    "\n",
    "    all_scenarios_appointment_delayed_mean[scenario_names[draw]] = all_years_data_delayed_mean\n",
    "    all_scenarios_appointment_cancelled_mean[scenario_names[draw]] = all_years_data_cancelled_mean\n",
    "    all_scenarios_dalys_mean[scenario_names[draw]] = all_years_dalys_mean\n"
   ],
   "id": "b678b62af30061a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n",
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n",
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n",
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8185894.885388111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n",
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n",
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8377869.203356011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:457: UserWarning: This function uses MEAN as the central measure. We now recommend using MEDIAN instead. This can be done by using the function `compute_summary_statistics`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plots",
   "id": "901224d7b2aa8106"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:28:57.075743Z",
     "start_time": "2025-12-01T14:28:57.043357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Now create the plots with dual y-axes\n",
    "appointment_delayed_scenarios = {}\n",
    "appointment_cancelled_scenarios = {}\n",
    "daly_scenarios = {}\n",
    "\n",
    "for scenario_name in scenario_names:\n",
    "    if scenario_name == \"Baseline\":\n",
    "        baseline_length = len(target_year_sequence)\n",
    "        appointment_delayed_scenarios[scenario_name] = [0.0] * baseline_length\n",
    "        appointment_cancelled_scenarios[scenario_name] = [0.0] * baseline_length\n",
    "        \n",
    "        dalys_all_years = [\n",
    "            value for year in daly_by_scenario.keys()\n",
    "            for value in daly_by_scenario[year].values.tolist()\n",
    "        ]\n",
    "        daly_scenarios[scenario_name] = dalys_all_years\n",
    "        continue\n",
    "    \n",
    "    if main_text:\n",
    "        if \"ssp245\" not in scenario_name:\n",
    "            continue\n",
    "        \n",
    "    delayed_by_scenario = all_scenarios_appointment_delayed_mean[scenario_name]\n",
    "    cancelled_by_scenario = all_scenarios_appointment_cancelled_mean[scenario_name]\n",
    "    daly_by_scenario = all_scenarios_dalys_mean[scenario_name]\n",
    "\n",
    "    delayed_all_years = [\n",
    "        value for year in delayed_by_scenario.keys()\n",
    "        for value in delayed_by_scenario[year].values.tolist()\n",
    "    ]\n",
    "    cancelled_all_years = [\n",
    "        value for year in cancelled_by_scenario.keys()\n",
    "        for value in cancelled_by_scenario[year].values.tolist()\n",
    "    ]\n",
    "    \n",
    "    dalys_all_years = [\n",
    "        value for year in daly_by_scenario.keys()\n",
    "        for value in daly_by_scenario[year].values.tolist()\n",
    "    ]\n",
    "    \n",
    "    appointment_delayed_scenarios[scenario_name] = delayed_all_years\n",
    "    appointment_cancelled_scenarios[scenario_name] = cancelled_all_years\n",
    "    daly_scenarios[scenario_name] = dalys_all_years\n",
    "\n",
    "if main_text:\n",
    "    scenario_names_filtered = [name for name in appointment_delayed_scenarios.keys() if \"ssp245\" in name]\n",
    "else:\n",
    "    scenario_names_filtered = scenario_names\n",
    "\n",
    "n_scenarios = len(scenario_names_filtered)\n",
    "n_cols = min(3, n_scenarios)\n",
    "n_rows = (n_scenarios + n_cols - 1) // n_cols  \n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6 * n_rows))\n",
    "if n_scenarios == 1:\n",
    "    axes = [axes]\n",
    "else:\n",
    "    axes = axes.flatten() if n_scenarios > 1 else [axes]\n",
    "\n",
    "for i, scenario_name in enumerate(scenario_names_filtered):\n",
    "    ax1 = axes[i]\n",
    "    \n",
    "    delayed_data = np.array(appointment_delayed_scenarios[scenario_name], dtype=float) * 100\n",
    "    cancelled_data = np.array(appointment_cancelled_scenarios[scenario_name], dtype=float) * 100\n",
    "    total_data = delayed_data + cancelled_data\n",
    "    daly_data = np.array(daly_scenarios[scenario_name], dtype=float)\n",
    "    \n",
    "    n_months = len(delayed_data)\n",
    "    start_date = pd.date_range(start='2026-01', periods=n_months, freq='MS')\n",
    "    \n",
    "    # Plot appointment disruptions on primary y-axis\n",
    "    line1 = ax1.plot(start_date, delayed_data, label=\"Delayed\", linewidth=2, color='#FF8C00')\n",
    "    line2 = ax1.plot(start_date, cancelled_data, label=\"Cancelled\", linewidth=2, color='#DC143C')\n",
    "    line3 = ax1.plot(start_date, total_data, label=\"Total Disrupted\", linewidth=2, color='#4169E1', linestyle='--')\n",
    "    \n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax1.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    ax1.set_xlabel(\"Time Period\", fontsize=12)\n",
    "    ax1.set_ylabel(\"% Disrupted\", fontsize=12, color='#4169E1')\n",
    "    ax1.tick_params(axis='y', labelcolor='#4169E1')\n",
    "    ax1.set_title(f\"{scenario_name}\", fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, linestyle=':')\n",
    "    \n",
    "    # Create secondary y-axis for DALYs\n",
    "    ax2 = ax1.twinx()\n",
    "    line4 = ax2.plot(start_date, daly_data, label=\"DALYs\", linewidth=2, color='#2E8B57', linestyle='-.')\n",
    "    ax2.set_ylabel(\"DALYs\", fontsize=12, color='#2E8B57')\n",
    "    ax2.tick_params(axis='y', labelcolor='#2E8B57')\n",
    "    \n",
    "    # Combine legends from both axes\n",
    "    lines = line1 + line2 + line3 + line4\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='best', fontsize=10)\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_folder / f\"{PREFIX_ON_FILENAME}_delayed_cancelled_dalys.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "3d7ccef6e6e4eac4",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[81], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m appointment_delayed_scenarios[scenario_name] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.0\u001B[39m] \u001B[38;5;241m*\u001B[39m baseline_length\n\u001B[1;32m     10\u001B[0m appointment_cancelled_scenarios[scenario_name] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.0\u001B[39m] \u001B[38;5;241m*\u001B[39m baseline_length\n\u001B[0;32m---> 12\u001B[0m dalys_all_years \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43myear\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdaly_by_scenario\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdaly_by_scenario\u001B[49m\u001B[43m[\u001B[49m\u001B[43myear\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     16\u001B[0m daly_scenarios[scenario_name] \u001B[38;5;241m=\u001B[39m dalys_all_years\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[81], line 14\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      9\u001B[0m appointment_delayed_scenarios[scenario_name] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.0\u001B[39m] \u001B[38;5;241m*\u001B[39m baseline_length\n\u001B[1;32m     10\u001B[0m appointment_cancelled_scenarios[scenario_name] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.0\u001B[39m] \u001B[38;5;241m*\u001B[39m baseline_length\n\u001B[1;32m     12\u001B[0m dalys_all_years \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     13\u001B[0m     value \u001B[38;5;28;01mfor\u001B[39;00m year \u001B[38;5;129;01min\u001B[39;00m daly_by_scenario\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdaly_by_scenario\u001B[49m\u001B[43m[\u001B[49m\u001B[43myear\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     15\u001B[0m ]\n\u001B[1;32m     16\u001B[0m daly_scenarios[scenario_name] \u001B[38;5;241m=\u001B[39m dalys_all_years\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.float64' object has no attribute 'values'"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "390/12",
   "id": "2b7453a65ac33566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add in weather for these",
   "id": "144776c5dc69dffc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ssps = [\"ssp245\"]\n",
    "models = [\"lowest\", \"mean\", \"highest\"]\n",
    "service = \"ANC\"\n",
    "\n",
    "for ssp_scenario in ssps:\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6 * n_rows))\n",
    "\n",
    "    for i, model_type in enumerate(models):\n",
    "        ax = axes[i]\n",
    "        weather_data_prediction_monthly_original = pd.read_csv(\n",
    "            f\"/Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL/{ssp_scenario}/{model_type}_monthly_prediction_weather_by_facility_{service}.csv\",\n",
    "            dtype={'column_name': 'float64'}\n",
    "        )\n",
    "        \n",
    "        mask = (weather_data_prediction_monthly_original.index > 23) & \\\n",
    "               (weather_data_prediction_monthly_original.index < (10*22))\n",
    "        weather_data_prediction_monthly_original = weather_data_prediction_monthly_original.loc[mask].reset_index(drop=True)\n",
    "\n",
    "        weather_data_prediction_monthly_average_facilities = weather_data_prediction_monthly_original.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "        yearly_precip = weather_data_prediction_monthly_average_facilities.groupby(weather_data_prediction_monthly_average_facilities.index // 12).sum()\n",
    "        \n",
    "        scenario_name = f\"{ssp_scenario}_{model_type}\"    \n",
    "        delayed_data = np.array(appointment_delayed_scenarios[scenario_name], dtype=float) * 100\n",
    "        cancelled_data = np.array(appointment_cancelled_scenarios[scenario_name], dtype=float) * 100\n",
    "        total_data = delayed_data + cancelled_data\n",
    "        \n",
    "        n_years = len(delayed_data)\n",
    "        start_date = pd.date_range(start='2026-01', periods=n_years, freq='Y')\n",
    "\n",
    "        # Plot precipitation on primary y-axis\n",
    "        color_precip = '#009DDC'\n",
    "        ax.plot(start_date, yearly_precip[2:], label='Precipitation', color=color_precip, linewidth=2, linestyle='--')\n",
    "        ax.set_xlabel(\"Year\")\n",
    "        ax.set_ylabel(\"Cumulative precipitation (mm)\", color=color_precip)\n",
    "        ax.tick_params(axis='y', labelcolor=color_precip)\n",
    "        \n",
    "        # Create secondary y-axis for appointment disruptions\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(start_date, delayed_data, label=\"Delayed\", linewidth=2, color='#FF8C00')\n",
    "        ax2.plot(start_date, cancelled_data, label=\"Cancelled\", linewidth=2, color='#DC143C')\n",
    "        ax2.plot(start_date, total_data, label=\"Total Disrupted\", linewidth=2, color='black')\n",
    "        ax2.set_ylabel(\"Appointment Disruption (%)\")\n",
    "        ax2.tick_params(axis='y')\n",
    "        \n",
    "        ax.set_title(f\"{ssp_scenario}, {model_type}\")\n",
    "        \n",
    "        # Combine legends from both axes\n",
    "        lines1, labels1 = ax.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "5ac5e25aae98c4d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now only mean for main text ",
   "id": "96ff65eb9ff1885b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ssps = [\"ssp245\"]\n",
    "model_type = \"mean\"  # only the middle panel\n",
    "service = \"ANC\"\n",
    "\n",
    "for ssp_scenario in ssps:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))  # single panel\n",
    "    \n",
    "    # Load weather data\n",
    "    weather_data_prediction_monthly = pd.read_csv(\n",
    "        f\"/Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL/{ssp_scenario}/{model_type}_monthly_prediction_weather_by_facility_{service}.csv\",\n",
    "        dtype={'column_name': 'float64'}\n",
    "    )\n",
    "\n",
    "    # Subset relevant months\n",
    "    mask = (weather_data_prediction_monthly.index > 23) & \\\n",
    "           (weather_data_prediction_monthly.index < (10*22))\n",
    "    weather_data_prediction_monthly = weather_data_prediction_monthly.loc[mask].reset_index(drop=True)\n",
    "\n",
    "    # Average across facilities\n",
    "    weather_data_avg = weather_data_prediction_monthly.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "    # Yearly cumulative precipitation\n",
    "    yearly_precip = weather_data_avg.groupby(weather_data_avg.index // 12).sum()\n",
    "\n",
    "    # Load appointment disruption data\n",
    "    scenario_name = f\"{ssp_scenario}_{model_type}\"    \n",
    "    delayed_data = np.array(appointment_delayed_scenarios[scenario_name], dtype=float) * 100\n",
    "    cancelled_data = np.array(appointment_cancelled_scenarios[scenario_name], dtype=float) * 100\n",
    "    total_data = delayed_data + cancelled_data\n",
    "\n",
    "    n_years = len(delayed_data)\n",
    "    start_date = pd.date_range(start='2026-01', periods=n_years, freq='Y')\n",
    "\n",
    "    # Plot precipitation on primary y-axis\n",
    "    color_precip = '#1C6E8C'\n",
    "    ax.plot(start_date, yearly_precip[2:], label='Precipitation', color=color_precip,\n",
    "            linewidth=2, linestyle='--')\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Cumulative Precipitation (mm)\", color=color_precip)\n",
    "    ax.tick_params(axis='y', labelcolor=color_precip)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Secondary y-axis for appointment disruptions\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(start_date, delayed_data, label=\"Delayed\", linewidth=2, color='#FEB95F')\n",
    "    ax2.plot(start_date, cancelled_data, label=\"Cancelled\", linewidth=2, color='#f07167')\n",
    "    ax2.plot(start_date, total_data, label=\"Total Disrupted\", linewidth=2, color='#5A716A')\n",
    "    ax2.set_ylabel(\"Appointment Disruption (%)\", rotation = -90, labelpad=25)\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left', frameon=False)\n",
    "    ax.text(-0.0, 1.05, '(C)', transform=ax.transAxes,\n",
    "                   fontsize=14, va='top', ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "eb7346cfdadc06f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get predicted disruptions from linear model",
   "id": "829ded0922162b38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "climate_ssps = [\"ssp126\", \"ssp245\", \"ssp585\"]\n",
    "climate_model_ensemble_models = [\"lowest\", \"mean\", \"highest\"]\n",
    "\n",
    "climate_all_scenarios = {}\n",
    "climate_summary_stats = {}\n",
    "\n",
    "for ssp in climate_ssps:\n",
    "    for model in climate_model_ensemble_models:\n",
    "        scenario_key = f\"{ssp}_{model}\"\n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            f'/Users/rem76/PycharmProjects/TLOmodel/resources/climate_change_impacts/'\n",
    "            f'ResourceFile_Precipitation_Disruptions_{ssp}_{model}.csv'\n",
    "        )\n",
    "        df = df[(df[\"year\"] > 2025) & (df[\"year\"] <= 2041)]\n",
    "        \n",
    "        # average per year-month\n",
    "        avg_df = df.groupby([\"year\", \"month\"], as_index=False)[\"mean_all_service\"].mean()\n",
    "        values = avg_df[\"mean_all_service\"].values.tolist()\n",
    "        \n",
    "        # store full time series\n",
    "        climate_all_scenarios[scenario_key] = values\n",
    "        \n",
    "        # compute summary statistics\n",
    "        climate_summary_stats[scenario_key] = {\n",
    "            \"min\": float(avg_df[\"mean_all_service\"].min()) ,\n",
    "            \"max\": float(avg_df[\"mean_all_service\"].max()) ,\n",
    "            \"mean\": float(avg_df[\"mean_all_service\"].mean() )\n",
    "        }\n",
    "\n"
   ],
   "id": "810bc11b5e7e0e8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot predicted vs modelled disruptions",
   "id": "61c29b2cd7b65e9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "appointment_all_scenarios = {}\n",
    "for scenario_name in scenario_names:\n",
    "    if scenario_name == \"Baseline\":\n",
    "        continue\n",
    "    appointment_by_scenario = all_scenarios_appointment_difference_mean[scenario_name]\n",
    "    for year in appointment_by_scenario.keys():\n",
    "            appointment_all_years = [\n",
    "        value\n",
    "        for year in appointment_by_scenario.keys()\n",
    "        for value in appointment_by_scenario[year].values.tolist()\n",
    "    ]\n",
    "        \n",
    "    appointment_all_scenarios[scenario_name] = appointment_all_years\n",
    "\n",
    "\n",
    "scenario_names = [name for name in appointment_all_scenarios.keys() if name != \"baseline\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()  # Flatten to easily index\n",
    "\n",
    "for i, scenario_name in enumerate(scenario_names):\n",
    "    ax = axes[i]\n",
    "    ax.plot(np.array(appointment_all_scenarios[scenario_name], dtype=float) * 0.6, label=\"TLO\")\n",
    "    ax.plot(climate_all_scenarios[scenario_name], label=\"Predicted\")\n",
    "    \n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.set_title(f\"{scenario_name}\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()"
   ],
   "id": "6f461c55090b435",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.dates as mdates\n",
    "appointment_all_scenarios = {}\n",
    "for scenario_name in scenario_names:\n",
    "    if scenario_name == \"Baseline\":\n",
    "        continue\n",
    "    # Filter for only SSP 2.45 scenarios\n",
    "    if \"ssp245\" not in scenario_name:\n",
    "        continue\n",
    "        \n",
    "    appointment_by_scenario = all_scenarios_appointment_difference_mean[scenario_name]\n",
    "    # Collect all values across all years\n",
    "    appointment_all_years = [\n",
    "        value\n",
    "        for year in appointment_by_scenario.keys()\n",
    "        for value in appointment_by_scenario[year].values.tolist()\n",
    "    ]\n",
    "        \n",
    "    appointment_all_scenarios[scenario_name] = appointment_all_years\n",
    "\n",
    "# Filter scenario names for SSP 2.45\n",
    "scenario_names_filtered = [name for name in appointment_all_scenarios.keys() if \"ssp245\" in name]\n",
    "\n",
    "# Adjust subplot grid based on number of SSP 2.45 scenarios\n",
    "n_scenarios = len(scenario_names_filtered)\n",
    "n_cols = min(3, n_scenarios)\n",
    "n_rows = (n_scenarios + n_cols - 1) // n_cols  \n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6 * n_rows))\n",
    "if n_scenarios == 1:\n",
    "    axes = [axes]\n",
    "else:\n",
    "    axes = axes.flatten() if n_scenarios > 1 else [axes]\n",
    "\n",
    "for i, scenario_name in enumerate(scenario_names_filtered):\n",
    "    ax = axes[i]\n",
    "    # Convert to % by multiplying by 100\n",
    "    data_points = np.array(appointment_all_scenarios[scenario_name], dtype=float) * 100\n",
    "    \n",
    "    # Create month labels starting from Jan 2012\n",
    "    n_months = len(data_points)\n",
    "    start_date = pd.date_range(start='2026-01', periods=n_months, freq='MS')\n",
    "    \n",
    "    ax.plot(start_date, data_points, label=\"TLO % Delayed\")\n",
    "    \n",
    "    # Format x-axis to show dates nicely\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    ax.set_xlabel(\"Time Period\")\n",
    "    ax.set_ylabel(\"% Disrupted\")\n",
    "    ax.set_title(f\"{scenario_name}\")\n",
    "    ax.grid(False)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ],
   "id": "8089e3702950e417",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " ssps = [\"ssp126\", \"ssp245\", \"ssp585\"]\n",
    "models = [\"lowest\", \"mean\", \"highest\"]\n",
    "service = \"ANC\"\n",
    "\n",
    "for ssp_scenario in ssps:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for model_type in models:\n",
    "        weather_data_prediction_monthly_original = pd.read_csv(\n",
    "            f\"/Users/rem76/Desktop/Climate_change_health/Data/Precipitation_data/Downscaled_CMIP6_data_CIL/{ssp_scenario}/{model_type}_monthly_prediction_weather_by_facility_{service}.csv\",\n",
    "            dtype={'column_name': 'float64'}\n",
    "        )\n",
    "        \n",
    "        mask = (weather_data_prediction_monthly_original.index > 23) & \\\n",
    "               (weather_data_prediction_monthly_original.index < (12*18))\n",
    "        weather_data_prediction_monthly_original = weather_data_prediction_monthly_original.loc[mask].reset_index(drop=True)\n",
    "\n",
    "        weather_data_prediction_monthly_average_facilities = weather_data_prediction_monthly_original.iloc[:, 1:].mean(axis=1)\n",
    "        plt.plot(weather_data_prediction_monthly_average_facilities, label=model_type)\n",
    "    \n",
    "    plt.xticks(ticks=range(0,int(len(weather_data_prediction_monthly_original)), 12), labels=range(2026, 2026 + int(len(weather_data_prediction_monthly_original)/12), 1))\n",
    "    plt.title(f\"Predicted Monthly Weather by Facility â€“ {ssp_scenario}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Predicted Weather\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "890e79ae3dd69062",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
