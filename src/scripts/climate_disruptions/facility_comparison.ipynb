{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facility-by-Facility Comparison: TLO Model vs ANC Disruption Data\n",
    "\n",
    "Matches TLO model-estimated disruption rates directly to ANC-derived disruption probabilities\n",
    "at the individual facility level via `RealFacility_ID`.\n",
    "\n",
    "**Structure:**\n",
    "1. Configuration & imports\n",
    "2. Load ANC disruption data (ground truth)\n",
    "3. Build `Facility_ID` → `RealFacility_ID` mapping from weather event logs\n",
    "4. Extract TLO disrupted counts by `RealFacility_ID` (climate run, all 200 draws)\n",
    "5. Extract TLO baseline denominator in `RealFacility_ID` space\n",
    "6. Compute per-facility disruption fractions & merge with ANC\n",
    "7. Scatter: TLO model output vs ANC input, facility-level\n",
    "8. Facility-level time series panels (top/bottom disrupted)\n",
    "9. Summary statistics & residual analysis"
   ],
   "id": "43d5556acacfdcaa"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:35:33.166466Z",
     "start_time": "2026-02-23T11:35:33.158488Z"
    }
   },
   "source": [
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "#  0.  CONFIGURATION  — edit paths here\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "from pathlib import Path\n",
    "\n",
    "# TLO simulation output folders\n",
    "RESULTS_CLIMATE  = Path('/Users/rem76/PycharmProjects/TLOmodel/outputs/rm916@ic.ac.uk/climate_scenario_runs_lhs_param_scan-2026-02-03T101537Z')\n",
    "RESULTS_BASELINE = Path('/Users/rem76/PycharmProjects/TLOmodel/outputs/rm916@ic.ac.uk/baseline_run_with_pop-2026-02-05T113912Z')\n",
    "\n",
    "# ANC / climate data files\n",
    "SSP     = 'ssp245'\n",
    "MODEL   = 'mean'\n",
    "SERVICE = 'ANC'\n",
    "\n",
    "ANC_PREDICTIONS_CSV = Path(f'/Users/rem76/Desktop/Climate_Change_Health/Data/weather_predictions_with_X_{SSP}_{MODEL}_{SERVICE}.csv')\n",
    "DISRUPTIONS_CSV     = Path(f'/Users/rem76/PycharmProjects/TLOmodel/resources/climate_change_impacts/ResourceFile_Precipitation_Disruptions_{SSP}_{MODEL}.csv')\n",
    "TLO_MFL_CSV         = Path('/Users/rem76/PycharmProjects/TLOmodel/resources/healthsystem/organisation/ResourceFile_Master_Facilities_List.csv')\n",
    "\n",
    "# Where to write figures\n",
    "OUTPUT_DIR = Path('/Users/rem76/Desktop/Climate_Change_Health')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Analysis window\n",
    "min_year   = 2025\n",
    "max_year   = 2036   # exclusive\n",
    "spacing_of_years = 1\n",
    "# Analysis params\n",
    "climate_sensitivity_analysis = False\n",
    "main_text = True\n",
    "parameter_uncertainty_analysis = False\n",
    "\n",
    "if parameter_uncertainty_analysis:\n",
    "    scenario_names = range(0,  200, 1)\n",
    "    scenarios_of_interest = scenario_names\n",
    "    suffix = \"parameter_UA\"\n",
    "if main_text:\n",
    "    scenario_names = [\n",
    "        \"Baseline\",\n",
    "        \"Best Case\",\n",
    "        \"Worst Case\"\n",
    "    ]\n",
    "    suffix = \"main_text\"\n",
    "    scenarios_of_interest = [0, 1, 2]\n",
    "\n",
    "# Draw/folder 0 in the climate run is the no-disruption baseline — skip it\n",
    "FIRST_CLIMATE_DRAW = 1   # draws 1 … N_DRAWS-1 are the actual LHS climate runs\n",
    "\n",
    "# District name harmonisation  (split cities → parent district)\n",
    "DISTRICT_MERGE = {\n",
    "    'Mzimba North': 'Mzimba', 'Mzimba South': 'Mzimba',\n",
    "    'Blantyre City': 'Blantyre', 'Zomba City': 'Zomba',\n",
    "    'Lilongwe City': 'Lilongwe',\n",
    "}"
   ],
   "id": "2b990035b65fdd0f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:01:40.289967Z",
     "start_time": "2026-02-23T11:01:40.287143Z"
    }
   },
   "source": [
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "#  1.  IMPORTS\n",
    "# ══════════════════════════════════════════════════════════════════════════════\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from scipy import stats as scipy_stats\n",
    "from collections import defaultdict\n",
    "\n",
    "from tlo import Date\n",
    "from tlo.analysis.utils import extract_results, summarize\n",
    "\n",
    "TARGET_YEARS = list(range(MIN_YEAR, MAX_YEAR))\n"
   ],
   "id": "e7230d97e974544f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis years : 2025 – 2035  (11 years)\n",
      "Parameter draws: 3\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load ANC disruption data"
   ],
   "id": "b0bc6a32f4a123ec"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:01:40.350107Z",
     "start_time": "2026-02-23T11:01:40.312590Z"
    }
   },
   "source": [
    "# ── ANC resource file: disruption probability by facility / year / month ──────\n",
    "disruptions_df = pd.read_csv(DISRUPTIONS_CSV)\n",
    "disruptions_df = disruptions_df.rename(columns={'Unnamed: 0': 'index_col'})\n",
    "\n",
    "# Annual mean disruption probability per facility  (average across 12 months)\n",
    "anc_annual = (\n",
    "    disruptions_df\n",
    "    .groupby(['RealFacility_ID', 'year'])['disruption']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'disruption': 'anc_prob', 'year': 'Year'})\n",
    ")\n",
    "anc_annual['anc_pct'] = anc_annual['anc_prob'] * 100\n",
    "\n",
    "# Restrict to analysis window\n",
    "anc_annual = anc_annual[anc_annual['Year'].between(min_year, max_year - 1)]\n",
    "\n",
    "print(f'ANC data: {anc_annual[\"RealFacility_ID\"].nunique()} unique facilities, '\n",
    "      f'{anc_annual[\"Year\"].nunique()} years')\n",
    "print(f'  Mean annual disruption probability: {anc_annual[\"anc_pct\"].mean():.2f}%')\n",
    "anc_annual.head()"
   ],
   "id": "2f20a63b9ef441f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANC data: 328 unique facilities, 11 years\n",
      "  Mean annual disruption probability: 0.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         RealFacility_ID  Year  anc_prob   anc_pct\n",
       "0  Area 30 Police Clinic  2025  0.006528  0.652783\n",
       "1  Area 30 Police Clinic  2026  0.003169  0.316924\n",
       "2  Area 30 Police Clinic  2027  0.002392  0.239246\n",
       "3  Area 30 Police Clinic  2028  0.010278  1.027783\n",
       "4  Area 30 Police Clinic  2029  0.010013  1.001276"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RealFacility_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>anc_prob</th>\n",
       "      <th>anc_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area 30 Police Clinic</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.652783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Area 30 Police Clinic</td>\n",
       "      <td>2026</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.316924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Area 30 Police Clinic</td>\n",
       "      <td>2027</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.239246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Area 30 Police Clinic</td>\n",
       "      <td>2028</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>1.027783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Area 30 Police Clinic</td>\n",
       "      <td>2029</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>1.001276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:01:40.630629Z",
     "start_time": "2026-02-23T11:01:40.350930Z"
    }
   },
   "source": [
    "# ── ANC predictions file: facility metadata and expected attendance ────────────\n",
    "# (used for district / facility-type enrichment, not strictly needed for matching)\n",
    "anc_pred = pd.read_csv(ANC_PREDICTIONS_CSV)\n",
    "anc_pred = anc_pred.rename(columns={'Facility_ID': 'RealFacility_ID'})\n",
    "anc_pred['District'] = anc_pred['District'].replace(DISTRICT_MERGE)\n",
    "\n",
    "# Build a per-facility metadata table: one row per RealFacility_ID\n",
    "fac_meta = (\n",
    "    anc_pred[['RealFacility_ID', 'District', 'Facility_Type']]\n",
    "    .drop_duplicates(subset='RealFacility_ID')\n",
    "    .set_index('RealFacility_ID')\n",
    ")\n",
    "\n",
    "print(f'Facility metadata loaded: {len(fac_meta)} facilities')"
   ],
   "id": "a1e1015ab4d3cf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facility metadata loaded: 329 facilities\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions to extract data",
   "id": "36a73d9ba0818c3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:35:46.021126Z",
     "start_time": "2026-02-23T11:35:46.012039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_year_sequence = range(min_year, max_year, spacing_of_years)\n",
    "\n",
    "def get_num_treatments_total_delayed(_df):\n",
    "    \"\"\"Count total number of delayed HSI events\"\"\"\n",
    "    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n",
    "    _df = _df.loc[_df[\"date\"].between(*TARGET_PERIOD)]\n",
    "    return pd.Series(len(_df), name=\"total\")\n",
    "\n",
    "def get_num_treatments_total_cancelled(_df):\n",
    "    \"\"\"Count total number of cancelled HSI events\"\"\"\n",
    "    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n",
    "    _df = _df.loc[_df[\"date\"].between(*TARGET_PERIOD)]\n",
    "    return pd.Series(len(_df), name=\"total\")\n",
    "\n",
    "def get_num_treatments_total(_df):\n",
    "    \"\"\"Sum all treatment counts\"\"\"\n",
    "    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n",
    "    _df = _df.loc[_df[\"date\"].between(*TARGET_PERIOD)]\n",
    "    total = {}\n",
    "    for d in _df[\"hsi_event_key_to_counts\"]:\n",
    "        for k, v in d.items():\n",
    "            total[k] = total.get(k, 0) + v\n",
    "    return pd.Series(sum(total.values()), name=\"total\")\n",
    "\n",
    "def get_num_dalys_total(_df):\n",
    "    \"\"\"Return total number of DALYS (Stacked) by label (total by age-group within the TARGET_PERIOD)\"\"\"\n",
    "    return pd.Series(_df \\\n",
    "        .loc[_df.year.between(*[i.year for i in TARGET_PERIOD])] \\\n",
    "        .drop(columns=['date', 'sex', 'age_range', 'year']) \\\n",
    "        .sum().sum(), name=\"total\")\n",
    "\n",
    "def get_num_dalys_by_month(_df):\n",
    "    \"\"\"Sum all DALYs across all causes by month for the target year\"\"\"\n",
    "    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n",
    "    _df = _df.loc[_df[\"date\"].between(*TARGET_PERIOD)]\n",
    "    disease_columns = [col for col in _df.columns\n",
    "                      if col not in ['age_range', 'month', 'sex', 'year', 'date']]\n",
    "    return _df.groupby('month')[disease_columns].sum().sum(axis=1)\n",
    "\n",
    "def get_population_for_year(_df):\n",
    "    \"\"\"Returns the population in the year of interest\"\"\"\n",
    "    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n",
    "    filtered_df = _df.loc[_df[\"date\"].between(*TARGET_PERIOD)]\n",
    "    numeric_df = filtered_df.drop(columns=[\"female\", \"male\"], errors=\"ignore\")\n",
    "    return numeric_df.sum(numeric_only=True)\n",
    "\n",
    "def get_num_treatments_by_real_facility_delayed(_df):\n",
    "    \"\"\"Count delayed HSI events grouped by RealFacility_ID\"\"\"\n",
    "    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n",
    "    _df = _df.loc[_df[\"date\"].between(*TARGET_PERIOD)]\n",
    "    _df = _df[_df[\"RealFacility_ID\"].notna() & (_df[\"RealFacility_ID\"] != \"unknown\")]\n",
    "    if len(_df) == 0:\n",
    "        return pd.Series(dtype=int)\n",
    "    return _df.groupby(\"RealFacility_ID\").size()\n",
    "\n",
    "def get_num_treatments_by_real_facility_cancelled(_df):\n",
    "    \"\"\"Count cancelled HSI events grouped by RealFacility_ID\"\"\"\n",
    "    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n",
    "    _df = _df.loc[_df[\"date\"].between(*TARGET_PERIOD)]\n",
    "    _df = _df[_df[\"RealFacility_ID\"].notna() & (_df[\"RealFacility_ID\"] != \"unknown\")]\n",
    "    if len(_df) == 0:\n",
    "        return pd.Series(dtype=int)\n",
    "    return _df.groupby(\"RealFacility_ID\").size()"
   ],
   "id": "631a52c156e02bb3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:38:35.095467Z",
     "start_time": "2026-02-23T11:38:35.085944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_folder_baseline = Path(\n",
    "    '/Users/rem76/PycharmProjects/TLOmodel/outputs/rm916@ic.ac.uk/baseline_run_with_pop-2026-02-20T161931Z')"
   ],
   "id": "dc2a69363ddb85e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:37:53.097365Z",
     "start_time": "2026-02-23T11:37:53.015348Z"
    }
   },
   "source": [
    "# Storage dictionaries\n",
    "all_scenarios_appointment_delayed_mean = {}\n",
    "all_scenarios_appointment_cancelled_mean = {}\n",
    "all_scenarios_dalys_mean = {}\n",
    "\n",
    "# Get denominators in RealFacility_ID space\n",
    "baseline_hsi_by_facility = {}\n",
    "\n",
    "for target_year in target_year_sequence:\n",
    "    TARGET_PERIOD = (Date(target_year, 1, 1), Date(target_year, 12, 31))\n",
    "\n",
    "    hsi_by_facility = summarize(extract_results(\n",
    "        results_folder_baseline,\n",
    "        module='tlo.methods.healthsystem.summary',\n",
    "        key='hsi_event_counts_by_facility_monthly',\n",
    "        custom_generate_series=get_hsi_counts_by_facility_monthly,\n",
    "        do_scaling=False\n",
    "    ), only_mean=True, collapse_columns=False)[0]\n",
    "\n",
    "    # Convert integer Facility_ID index → RealFacility_ID string index\n",
    "    hsi_by_facility.index = pd.Index([int(x) for x in hsi_by_facility.index], name='Facility_ID')\n",
    "    hsi_by_facility.index = hsi_by_facility.index.map(fac_id_to_real_s)\n",
    "    hsi_by_facility = hsi_by_facility[hsi_by_facility.index.notna()]\n",
    "    hsi_by_facility = hsi_by_facility.groupby(level=0).sum()\n",
    "    hsi_by_facility.index.name = 'RealFacility_ID'\n",
    "    baseline_hsi_by_facility[target_year] = hsi_by_facility\n",
    "\n",
    "# Main loop — skip draw 0 (no-disruption baseline folder)\n",
    "for draw in scenarios_of_interest:\n",
    "    print(draw)\n",
    "    all_years_data_delayed_mean = {}\n",
    "    all_years_data_cancelled_mean = {}\n",
    "    all_years_dalys_mean = {}\n",
    "\n",
    "    for target_year in target_year_sequence:\n",
    "        TARGET_PERIOD = (Date(target_year, 1, 1), Date(target_year, 12, 31))\n",
    "\n",
    "        # Get delayed counts by RealFacility_ID from climate folder (NUMERATOR)\n",
    "        num_delayed_by_facility = summarize(extract_results(\n",
    "            results_folder_climate,\n",
    "            module='tlo.methods.healthsystem.summary',\n",
    "            key='Weather_delayed_HSI_Event_full_info',\n",
    "            custom_generate_series=get_num_treatments_by_real_facility_delayed,\n",
    "            do_scaling=False\n",
    "        ), only_mean=True, collapse_columns=False)[draw]\n",
    "\n",
    "        # Get cancelled counts by RealFacility_ID from climate folder (NUMERATOR)\n",
    "        num_cancelled_by_facility = summarize(extract_results(\n",
    "            results_folder_climate,\n",
    "            module='tlo.methods.healthsystem.summary',\n",
    "            key='Weather_cancelled_HSI_Event_full_info',\n",
    "            custom_generate_series=get_num_treatments_by_real_facility_cancelled,\n",
    "            do_scaling=False\n",
    "        ), only_mean=True, collapse_columns=False)[draw]\n",
    "\n",
    "        # Align and divide by baseline\n",
    "        baseline_aligned, delayed_aligned = baseline_hsi_by_facility[target_year].align(num_delayed_by_facility, fill_value=0)\n",
    "        delayed_proportions = delayed_aligned / baseline_aligned\n",
    "\n",
    "        baseline_aligned, cancelled_aligned = baseline_hsi_by_facility[target_year].align(num_cancelled_by_facility, fill_value=0)\n",
    "        cancelled_proportions = cancelled_aligned / baseline_aligned\n",
    "\n",
    "        all_years_data_delayed_mean[target_year] = delayed_proportions\n",
    "        all_years_data_cancelled_mean[target_year] = cancelled_proportions\n",
    "\n",
    "    all_scenarios_appointment_delayed_mean[draw] = all_years_data_delayed_mean\n",
    "    all_scenarios_appointment_cancelled_mean[draw] = all_years_data_cancelled_mean\n",
    "    all_scenarios_dalys_mean[draw] = all_years_dalys_mean"
   ],
   "id": "36a23d81152c6b3f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_folder_baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m target_year \u001B[38;5;129;01min\u001B[39;00m target_year_sequence:\n\u001B[32m     10\u001B[39m     TARGET_PERIOD = (Date(target_year, \u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m), Date(target_year, \u001B[32m12\u001B[39m, \u001B[32m31\u001B[39m))\n\u001B[32m     12\u001B[39m     hsi_by_facility = summarize(extract_results(\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m         \u001B[43mresults_folder_baseline\u001B[49m,\n\u001B[32m     14\u001B[39m         module=\u001B[33m'\u001B[39m\u001B[33mtlo.methods.healthsystem.summary\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     15\u001B[39m         key=\u001B[33m'\u001B[39m\u001B[33mhsi_event_counts_by_facility_monthly\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     16\u001B[39m         custom_generate_series=get_hsi_counts_by_facility_monthly,\n\u001B[32m     17\u001B[39m         do_scaling=\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     18\u001B[39m     ), only_mean=\u001B[38;5;28;01mTrue\u001B[39;00m, collapse_columns=\u001B[38;5;28;01mFalse\u001B[39;00m)[\u001B[32m0\u001B[39m]\n\u001B[32m     20\u001B[39m     \u001B[38;5;66;03m# Convert integer Facility_ID index → RealFacility_ID string index\u001B[39;00m\n\u001B[32m     21\u001B[39m     hsi_by_facility.index = pd.Index([\u001B[38;5;28mint\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m hsi_by_facility.index], name=\u001B[33m'\u001B[39m\u001B[33mFacility_ID\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'results_folder_baseline' is not defined"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract TLO disrupted counts by `RealFacility_ID` — all draws"
   ],
   "id": "6991ef872265b1e"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T11:18:46.314403Z",
     "start_time": "2026-02-23T11:18:17.364899Z"
    }
   },
   "source": [
    "def _count_by_real_fac(_df):\n",
    "    \"\"\"Generic: count HSI events grouped by RealFacility_ID within TARGET_PERIOD.\"\"\"\n",
    "    print(_df)\n",
    "    _df['date'] = pd.to_datetime(_df['date'])\n",
    "    _df = _df.loc[_df['date'].between(*TARGET_PERIOD)]\n",
    "    _df = _df[_df['RealFacility_ID'].notna() & (_df['RealFacility_ID'] != 'unknown')]\n",
    "    if len(_df) == 0:\n",
    "        return pd.Series(dtype=int)\n",
    "    return _df.groupby('RealFacility_ID').size()\n",
    "\n",
    "\n",
    "# ── Extract once per year for delayed and cancelled ───────────────────────────\n",
    "# Result structures:\n",
    "#   delayed_raw[year]   → DataFrame  shape (n_facilities, n_draws)\n",
    "#   cancelled_raw[year] → DataFrame  shape (n_facilities, n_draws)\n",
    "\n",
    "delayed_raw   = {}\n",
    "cancelled_raw = {}\n",
    "\n",
    "for year in TARGET_YEARS:\n",
    "    TARGET_PERIOD = (Date(year, 1, 1), Date(year, 12, 31))\n",
    "    print(f'  extracting year {year}', end='\\r')\n",
    "\n",
    "    delayed_raw[year] = extract_results(\n",
    "        RESULTS_CLIMATE,\n",
    "        module='tlo.methods.healthsystem.summary',\n",
    "        key='Weather_delayed_HSI_Event_full_info',\n",
    "        custom_generate_series=_count_by_real_fac,\n",
    "        do_scaling=False,\n",
    "    ).fillna(0)\n",
    "\n",
    "    cancelled_raw[year] = extract_results(\n",
    "        RESULTS_CLIMATE,\n",
    "        module='tlo.methods.healthsystem.summary',\n",
    "        key='Weather_cancelled_HSI_Event_full_info',\n",
    "        custom_generate_series=_count_by_real_fac,\n",
    "        do_scaling=False,\n",
    "    ).fillna(0)\n",
    "\n",
    "print('\\nExtraction complete.')\n",
    "print(f'  Example year {TARGET_YEARS[0]}: delayed shape = {delayed_raw[TARGET_YEARS[0]].shape}')"
   ],
   "id": "85aeec461b232db8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  extracting year 2025\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 23\u001B[39m\n\u001B[32m     20\u001B[39m     TARGET_PERIOD = (Date(year, \u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m), Date(year, \u001B[32m12\u001B[39m, \u001B[32m31\u001B[39m))\n\u001B[32m     21\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33m  extracting year \u001B[39m\u001B[38;5;132;01m{\u001B[39;00myear\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m, end=\u001B[33m'\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m     delayed_raw[year] = \u001B[43mextract_results\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m        \u001B[49m\u001B[43mRESULTS_CLIMATE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     25\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtlo.methods.healthsystem.summary\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mWeather_delayed_HSI_Event_full_info\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcustom_generate_series\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_count_by_real_fac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdo_scaling\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m.fillna(\u001B[32m0\u001B[39m)\n\u001B[32m     31\u001B[39m     cancelled_raw[year] = extract_results(\n\u001B[32m     32\u001B[39m         RESULTS_CLIMATE,\n\u001B[32m     33\u001B[39m         module=\u001B[33m'\u001B[39m\u001B[33mtlo.methods.healthsystem.summary\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     36\u001B[39m         do_scaling=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     37\u001B[39m     ).fillna(\u001B[32m0\u001B[39m)\n\u001B[32m     39\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mExtraction complete.\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/TLOmodel/src/tlo/analysis/utils.py:364\u001B[39m, in \u001B[36mextract_results\u001B[39m\u001B[34m(results_folder, module, key, column, index, custom_generate_series, do_scaling)\u001B[39m\n\u001B[32m    361\u001B[39m             res[draw_run] = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    363\u001B[39m \u001B[38;5;66;03m# Use pd.concat to compile results (skips dict items where the values is None)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m364\u001B[39m _concat = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    365\u001B[39m _concat.columns.names = [\u001B[33m'\u001B[39m\u001B[33mdraw\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mrun\u001B[39m\u001B[33m'\u001B[39m]  \u001B[38;5;66;03m# name the levels of the columns multi-index\u001B[39;00m\n\u001B[32m    366\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _concat\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/pandas/core/reshape/concat.py:372\u001B[39m, in \u001B[36mconcat\u001B[39m\u001B[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[39m\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[32m    370\u001B[39m     copy = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m372\u001B[39m op = \u001B[43m_Concatenator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    373\u001B[39m \u001B[43m    \u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    374\u001B[39m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    375\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    376\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m=\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    377\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlevels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlevels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[43m=\u001B[49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m op.get_result()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tlo/lib/python3.11/site-packages/pandas/core/reshape/concat.py:452\u001B[39m, in \u001B[36m_Concatenator.__init__\u001B[39m\u001B[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[39m\n\u001B[32m    449\u001B[39m         keys = Index(clean_keys, name=name, dtype=\u001B[38;5;28mgetattr\u001B[39m(keys, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    451\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(objs) == \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m452\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mAll objects passed were None\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    454\u001B[39m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[32m    455\u001B[39m ndims = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[31mValueError\u001B[39m: All objects passed were None"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract baseline denominator (total HSI events) in `RealFacility_ID` space"
   ],
   "id": "6a35b3af32acecc5"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def _hsi_by_facility_int(_df):\n",
    "    \"\"\"Sum HSI event counts by integer Facility_ID within TARGET_PERIOD.\"\"\"\n",
    "    _df['date'] = pd.to_datetime(_df['date'])\n",
    "    _df = _df.loc[_df['date'].between(*TARGET_PERIOD)]\n",
    "    if len(_df) == 0:\n",
    "        return pd.Series(dtype=int)\n",
    "    totals = defaultdict(int)\n",
    "    for _, row in _df.iterrows():\n",
    "        for key, val in row['counts'].items():\n",
    "            if ':' in str(key):\n",
    "                fac_id = int(key.split(':')[0])\n",
    "                totals[fac_id] += val\n",
    "    return pd.Series(totals)\n",
    "\n",
    "\n",
    "baseline_by_real = {}  # year → pd.Series(index=RealFacility_ID, values=total HSI)\n",
    "\n",
    "for year in TARGET_YEARS:\n",
    "    TARGET_PERIOD = (Date(year, 1, 1), Date(year, 12, 31))\n",
    "    print(f'  baseline year {year}', end='\\r')\n",
    "\n",
    "    raw_int = extract_results(\n",
    "        RESULTS_BASELINE,\n",
    "        module='tlo.methods.healthsystem.summary',\n",
    "        key='hsi_event_counts_by_facility_monthly',\n",
    "        custom_generate_series=_hsi_by_facility_int,\n",
    "        do_scaling=False,\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Average across baseline draws (columns) → one value per integer Facility_ID\n",
    "    mean_int = raw_int.mean(axis=1)\n",
    "    mean_int.index = mean_int.index.astype(int)\n",
    "\n",
    "    # Map integer Facility_ID → RealFacility_ID\n",
    "    mapped = mean_int.copy()\n",
    "    mapped.index = mean_int.index.map(fac_id_to_real_s)\n",
    "    mapped = mapped[mapped.index.notna()]          # drop unmapped facilities\n",
    "    mapped = mapped.groupby(level=0).sum()         # sum if multiple TLO IDs → same name\n",
    "    mapped.index.name = 'RealFacility_ID'\n",
    "    baseline_by_real[year] = mapped\n",
    "\n",
    "print('\\nBaseline denominator ready.')\n",
    "print(f'  Year {TARGET_YEARS[0]}: {len(baseline_by_real[TARGET_YEARS[0]])} facilities covered')"
   ],
   "id": "fd52a32418669a32",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute per-facility disruption fractions & merge with ANC"
   ],
   "id": "cfdae26db5401e0b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Per draw, per year, per facility: disruption fraction ─────────────────────\n",
    "#\n",
    "# disruption_frac[year] → DataFrame  shape (n_facilities, n_draws)\n",
    "#                          values = (delayed + cancelled) / baseline\n",
    "\n",
    "disruption_frac = {}\n",
    "\n",
    "for year in TARGET_YEARS:\n",
    "    denom = baseline_by_real[year]              # Series  index=RealFacility_ID\n",
    "    del_df  = delayed_raw[year]                 # DataFrame index=RealFacility_ID, cols=draws\n",
    "    can_df  = cancelled_raw[year]\n",
    "\n",
    "    # Align all three to the same index\n",
    "    all_facs = denom.index.union(del_df.index).union(can_df.index)\n",
    "    denom    = denom.reindex(all_facs, fill_value=0)\n",
    "    del_df   = del_df.reindex(all_facs, fill_value=0)\n",
    "    can_df   = can_df.reindex(all_facs, fill_value=0)\n",
    "\n",
    "    total = del_df.add(can_df, fill_value=0)    # (delayed + cancelled) per draw\n",
    "\n",
    "    # Divide row-wise by denominator; NaN where denominator is 0\n",
    "    frac = total.divide(denom.replace(0, np.nan), axis=0)\n",
    "    disruption_frac[year] = frac\n",
    "\n",
    "print('Disruption fractions computed.')\n",
    "print(f'  Example year {TARGET_YEARS[0]}: shape = {disruption_frac[TARGET_YEARS[0]].shape}')"
   ],
   "id": "3f3f739e9e65835b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Summarise across draws: mean / median / IQR per (facility, year) ──────────\n",
    "\n",
    "summary_rows = []\n",
    "for year in TARGET_YEARS:\n",
    "    df = disruption_frac[year]\n",
    "    s  = pd.DataFrame({\n",
    "        'mean':   df.mean(axis=1),\n",
    "        'median': df.median(axis=1),\n",
    "        'p25':    df.quantile(0.25, axis=1),\n",
    "        'p75':    df.quantile(0.75, axis=1),\n",
    "        'p05':    df.quantile(0.05,  axis=1),\n",
    "        'p95':    df.quantile(0.95,  axis=1),\n",
    "    })\n",
    "    s.index.name = 'RealFacility_ID'\n",
    "    s = s.reset_index()\n",
    "    s['Year'] = year\n",
    "    summary_rows.append(s)\n",
    "\n",
    "tlo_summary = pd.concat(summary_rows, ignore_index=True)\n",
    "# Convert to %\n",
    "for col in ['mean', 'median', 'p25', 'p75', 'p05', 'p95']:\n",
    "    tlo_summary[col] *= 100\n",
    "\n",
    "print(f'TLO summary table: {tlo_summary.shape[0]} rows  ({tlo_summary[\"RealFacility_ID\"].nunique()} facilities × {len(TARGET_YEARS)} years)')"
   ],
   "id": "a7c5309d76c02e7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Merge TLO model summary with ANC disruption data on (RealFacility_ID, Year) ─\n",
    "\n",
    "comparison = tlo_summary.merge(\n",
    "    anc_annual,\n",
    "    on=['RealFacility_ID', 'Year'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Optionally enrich with facility metadata (district, type)\n",
    "comparison = comparison.merge(\n",
    "    fac_meta.reset_index(),\n",
    "    on='RealFacility_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop facilities with no meaningful baseline counts in TLO model\n",
    "# (mean TLO disruption NaN means the facility never appeared in the model outputs)\n",
    "comparison = comparison.dropna(subset=['mean', 'anc_pct'])\n",
    "\n",
    "n_fac   = comparison['RealFacility_ID'].nunique()\n",
    "n_years = comparison['Year'].nunique()\n",
    "print(f'Matched: {n_fac} facilities × {n_years} years = {len(comparison)} rows')\n",
    "comparison[['RealFacility_ID', 'Year', 'mean', 'p25', 'p75', 'anc_pct', 'District', 'Facility_Type']].head(8)"
   ],
   "id": "33c47f9ac7abe2e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scatter plot: TLO model output vs ANC input, facility-level"
   ],
   "id": "c0fae7792790a925"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "years_in_data  = sorted(comparison['Year'].unique())\n",
    "cmap           = plt.cm.plasma\n",
    "norm           = Normalize(vmin=min(years_in_data), vmax=max(years_in_data))\n",
    "axis_max       = max(comparison[['mean', 'anc_pct']].max()) * 1.1\n",
    "\n",
    "\n",
    "# ─── Panel A: every facility-year point, coloured by year ────────────────────\n",
    "ax = axes[0]\n",
    "for year in years_in_data:\n",
    "    sub = comparison[comparison['Year'] == year].dropna(subset=['mean', 'anc_pct'])\n",
    "    ax.scatter(\n",
    "        sub['anc_pct'], sub['mean'],\n",
    "        c=[cmap(norm(year))] * len(sub),\n",
    "        alpha=0.4, s=12, linewidths=0\n",
    "    )\n",
    "\n",
    "ax.plot([0, axis_max], [0, axis_max], 'k--', lw=1, alpha=0.5, label='1:1 line')\n",
    "\n",
    "sub_all = comparison.dropna(subset=['mean', 'anc_pct'])\n",
    "slope, intercept, r, p, _ = scipy_stats.linregress(sub_all['anc_pct'], sub_all['mean'])\n",
    "xs = np.linspace(0, axis_max, 100)\n",
    "ax.plot(xs, intercept + slope * xs, 'r-', lw=1.8,\n",
    "        label=f'OLS  slope={slope:.2f}  R²={r**2:.3f}')\n",
    "\n",
    "sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "fig.colorbar(sm, ax=ax, label='Year', shrink=0.85)\n",
    "ax.set_xlabel('ANC disruption probability (%)',  fontsize=10)\n",
    "ax.set_ylabel('TLO model disruption rate (%)\\n[mean across draws]', fontsize=10)\n",
    "ax.set_title('A) All facility-years\\n(coloured by year)', fontsize=11)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3, ls=':')\n",
    "\n",
    "\n",
    "# ─── Panel B: time-averaged with IQR error bars, coloured by Facility_Type ───\n",
    "ax = axes[1]\n",
    "fac_avg = (\n",
    "    comparison\n",
    "    .groupby('RealFacility_ID')[['mean', 'p25', 'p75', 'anc_pct', 'Facility_Type']]\n",
    "    .agg({'mean': 'mean', 'p25': 'mean', 'p75': 'mean',\n",
    "          'anc_pct': 'mean', 'Facility_Type': 'first'})\n",
    "    .reset_index()\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "# Colour by facility type (broad groups)\n",
    "type_colour = {\n",
    "    'Health Post': '#1f77b4', 'Health Centre': '#ff7f0e', 'Hospital': '#2ca02c',\n",
    "    'Other': '#9467bd'\n",
    "}\n",
    "def _broad_type(t):\n",
    "    if pd.isna(t): return 'Other'\n",
    "    t = t.lower()\n",
    "    if 'hospital' in t: return 'Hospital'\n",
    "    if 'health centre' in t or 'health center' in t: return 'Health Centre'\n",
    "    if 'health post' in t or 'dispensary' in t or 'village' in t: return 'Health Post'\n",
    "    return 'Other'\n",
    "\n",
    "fac_avg['broad_type'] = fac_avg['Facility_Type'].apply(_broad_type)\n",
    "\n",
    "for bt, grp in fac_avg.groupby('broad_type'):\n",
    "    ax.errorbar(\n",
    "        grp['anc_pct'], grp['mean'],\n",
    "        yerr=[grp['mean'] - grp['p25'], grp['p75'] - grp['mean']],\n",
    "        fmt='o', alpha=0.5, markersize=5, elinewidth=0.6, capsize=0,\n",
    "        color=type_colour.get(bt, '#9467bd'), label=bt\n",
    "    )\n",
    "\n",
    "ax.plot([0, axis_max], [0, axis_max], 'k--', lw=1, alpha=0.5)\n",
    "slope2, intercept2, r2, p2, _ = scipy_stats.linregress(\n",
    "    fac_avg['anc_pct'], fac_avg['mean'])\n",
    "ax.plot(xs, intercept2 + slope2 * xs, 'r-', lw=1.8,\n",
    "        label=f'OLS  slope={slope2:.2f}  R²={r2**2:.3f}')\n",
    "\n",
    "ax.set_xlabel('ANC disruption probability (%) [time-avg]', fontsize=10)\n",
    "ax.set_ylabel('TLO model disruption rate (%) [time-avg mean]', fontsize=10)\n",
    "ax.set_title('B) Per-facility averages\\n(IQR bars, coloured by type)', fontsize=11)\n",
    "ax.legend(fontsize=7, loc='upper left')\n",
    "ax.grid(True, alpha=0.3, ls=':')\n",
    "\n",
    "\n",
    "# ─── Panel C: residuals vs ANC disruption probability ─────────────────────────\n",
    "ax = axes[2]\n",
    "sub_all = comparison.dropna(subset=['mean', 'anc_pct']).copy()\n",
    "sub_all['residual'] = sub_all['mean'] - sub_all['anc_pct']\n",
    "\n",
    "ax.scatter(\n",
    "    sub_all['anc_pct'], sub_all['residual'],\n",
    "    c=[cmap(norm(y)) for y in sub_all['Year']],\n",
    "    alpha=0.35, s=12, linewidths=0\n",
    ")\n",
    "ax.axhline(0, color='k', lw=1, ls='--', alpha=0.5, label='Zero residual')\n",
    "ax.axhline(sub_all['residual'].mean(), color='r', lw=1.5,\n",
    "           label=f'Mean residual = {sub_all[\"residual\"].mean():.2f}%')\n",
    "\n",
    "# Smooth trend in residuals (LOWESS-style via rolling)\n",
    "bin_edges = np.percentile(sub_all['anc_pct'], np.arange(0, 101, 5))\n",
    "sub_all['anc_bin'] = pd.cut(sub_all['anc_pct'], bins=bin_edges)\n",
    "bin_median = sub_all.groupby('anc_bin')['residual'].median()\n",
    "bin_centres = [interval.mid for interval in bin_median.index]\n",
    "ax.plot(bin_centres, bin_median.values, 'orange', lw=2, zorder=5, label='Binned median')\n",
    "\n",
    "sm2 = ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm2.set_array([])\n",
    "fig.colorbar(sm2, ax=ax, label='Year', shrink=0.85)\n",
    "ax.set_xlabel('ANC disruption probability (%)', fontsize=10)\n",
    "ax.set_ylabel('TLO − ANC  (percentage-point residual)', fontsize=10)\n",
    "ax.set_title('C) Residuals\\n(TLO model minus ANC input)', fontsize=11)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3, ls=':')\n",
    "\n",
    "\n",
    "fig.suptitle(\n",
    "    f'Facility-level comparison: TLO model disruption vs ANC input disruption\\n'\n",
    "    f'n={n_fac} facilities | {N_DRAWS} parameter draws | {SSP.upper()} {MODEL} | {MIN_YEAR}–{MAX_YEAR-1}',\n",
    "    fontsize=12, fontweight='bold', y=1.01\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'facility_comparison_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'OLS all facility-years:  slope={slope:.3f}  R²={r**2:.3f}  p={p:.3g}')\n",
    "print(f'OLS time-averaged facs:  slope={slope2:.3f}  R²={r2**2:.3f}  p={p2:.3g}')\n",
    "print(f'Mean residual (TLO−ANC): {sub_all[\"residual\"].mean():.2f}%')\n",
    "print(f'Median |residual|:        {sub_all[\"residual\"].abs().median():.2f}%')"
   ],
   "id": "2c51a6b1301cb8ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Facility-level time-series panels\n",
    "\n",
    "Show the 20 highest- and 20 lowest-disrupted facilities by ANC estimate.\n",
    "Blue = TLO model median with IQR band. Purple = ANC disruption probability."
   ],
   "id": "e504d176d708c3c3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Rank facilities by mean ANC disruption probability ────────────────────────\n",
    "fac_anc_rank = (\n",
    "    anc_annual\n",
    "    .groupby('RealFacility_ID')['anc_pct']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Keep only facilities that also appear in the TLO outputs\n",
    "tlo_facs = set(tlo_summary['RealFacility_ID'].unique())\n",
    "fac_anc_rank = fac_anc_rank[fac_anc_rank.index.isin(tlo_facs)]\n",
    "\n",
    "N_PANEL = 20\n",
    "top_facs    = fac_anc_rank.head(N_PANEL).index.tolist()\n",
    "bottom_facs = fac_anc_rank.tail(N_PANEL).index.tolist()\n",
    "panel_facs  = top_facs + bottom_facs\n",
    "\n",
    "print(f'Top    {N_PANEL}: mean ANC disruption = {fac_anc_rank.head(N_PANEL).mean():.1f}%')\n",
    "print(f'Bottom {N_PANEL}: mean ANC disruption = {fac_anc_rank.tail(N_PANEL).mean():.1f}%')"
   ],
   "id": "2cf0051e4f8b1c6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pre-build per-facility TLO time series (median + IQR across draws) ──────────\n",
    "# Structure: fac_ts[facility] = dict with keys 'median', 'p25', 'p75'  (arrays of len n_years)\n",
    "\n",
    "fac_ts = {}\n",
    "DATE_INDEX = pd.to_datetime([f'{y}-07-01' for y in TARGET_YEARS])  # mid-year for plotting\n",
    "\n",
    "for fac in panel_facs:\n",
    "    med_arr, p25_arr, p75_arr = [], [], []\n",
    "    for year in TARGET_YEARS:\n",
    "        row = tlo_summary.loc[\n",
    "            (tlo_summary['RealFacility_ID'] == fac) &\n",
    "            (tlo_summary['Year'] == year)\n",
    "        ]\n",
    "        if len(row) == 0:\n",
    "            med_arr.append(np.nan)\n",
    "            p25_arr.append(np.nan)\n",
    "            p75_arr.append(np.nan)\n",
    "        else:\n",
    "            med_arr.append(row['median'].values[0])\n",
    "            p25_arr.append(row['p25'].values[0])\n",
    "            p75_arr.append(row['p75'].values[0])\n",
    "    fac_ts[fac] = {\n",
    "        'median': np.array(med_arr),\n",
    "        'p25':    np.array(p25_arr),\n",
    "        'p75':    np.array(p75_arr),\n",
    "    }\n",
    "\n",
    "print('Time series arrays built.')"
   ],
   "id": "d713feff3e526539",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "n_cols = 8\n",
    "n_rows = 5\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols,\n",
    "                         figsize=(3.0 * n_cols, 2.5 * n_rows),\n",
    "                         sharex=True, squeeze=True)\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for i, fac in enumerate(panel_facs):\n",
    "    ax    = axes_flat[i]\n",
    "    group = 'Top' if i < N_PANEL else 'Bottom'\n",
    "    title_colour = '#8B0000' if group == 'Top' else '#00008B'\n",
    "\n",
    "    # TLO model\n",
    "    ts = fac_ts[fac]\n",
    "    ax.fill_between(DATE_INDEX, ts['p25'], ts['p75'],\n",
    "                    color='#4169E1', alpha=0.25)\n",
    "    ax.plot(DATE_INDEX, ts['median'],\n",
    "            color='#4169E1', lw=1.5, label='TLO median')\n",
    "\n",
    "    # ANC disruption probability\n",
    "    anc_sub = anc_annual[anc_annual['RealFacility_ID'] == fac].sort_values('Year')\n",
    "    if len(anc_sub) > 0:\n",
    "        anc_dates = pd.to_datetime([f'{y}-07-01' for y in anc_sub['Year']])\n",
    "        ax.plot(anc_dates, anc_sub['anc_pct'],\n",
    "                color='purple', lw=1.5, ls='-', label='ANC data')\n",
    "\n",
    "    # ANC mean as dashed reference\n",
    "    ax.axhline(fac_anc_rank.get(fac, np.nan), color='purple',\n",
    "               lw=0.7, ls=':', alpha=0.5)\n",
    "\n",
    "    short = (fac[:22] + '…') if len(fac) > 22 else fac\n",
    "    ax.set_title(f'{short}\\n({group}, ANC≈{fac_anc_rank.get(fac, 0):.1f}%)',\n",
    "                 fontsize=5.5, pad=2, color=title_colour, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.2, ls=':')\n",
    "    ax.tick_params(labelsize=5)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(5))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=5)\n",
    "    if i == 0:\n",
    "        ax.legend(fontsize=5, loc='upper left', framealpha=0.7)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(panel_facs), len(axes_flat)):\n",
    "    axes_flat[j].set_visible(False)\n",
    "\n",
    "fig.supylabel('% appointments disrupted', fontsize=9, x=0.0)\n",
    "fig.suptitle(\n",
    "    f'Facility time series — TLO model (blue, IQR band) vs ANC data (purple)\\n'\n",
    "    f'Top {N_PANEL} highest-disrupted (red titles) & {N_PANEL} lowest-disrupted (blue titles) by ANC estimate',\n",
    "    fontsize=11, fontweight='bold'\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'facility_timeseries_top_bottom.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "8f2a6ba3bceb9399",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary statistics & residual diagnostics"
   ],
   "id": "75a1d77ce7ea8b68"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Overall summary ───────────────────────────────────────────────────────────\n",
    "comp = comparison.dropna(subset=['mean', 'anc_pct']).copy()\n",
    "comp['residual']    = comp['mean'] - comp['anc_pct']\n",
    "comp['abs_residual'] = comp['residual'].abs()\n",
    "\n",
    "print('═' * 55)\n",
    "print(f'  Facilities matched:          {comp[\"RealFacility_ID\"].nunique():>6}')\n",
    "print(f'  Facility-year rows:          {len(comp):>6}')\n",
    "print(f'  Mean ANC disruption:         {comp[\"anc_pct\"].mean():>6.2f}%')\n",
    "print(f'  Mean TLO disruption:         {comp[\"mean\"].mean():>6.2f}%')\n",
    "print(f'  Mean residual (TLO − ANC):   {comp[\"residual\"].mean():>6.2f}%')\n",
    "print(f'  Median |residual|:            {comp[\"abs_residual\"].median():>5.2f}%')\n",
    "print(f'  Pearson r:                   {comp[\"mean\"].corr(comp[\"anc_pct\"]):>6.3f}')\n",
    "print(f'  Spearman ρ:                  {comp[\"mean\"].corr(comp[\"anc_pct\"], method=\"spearman\"):>6.3f}')\n",
    "print('═' * 55)\n",
    "\n",
    "# ── By facility type ──────────────────────────────────────────────────────────\n",
    "comp['broad_type'] = comp['Facility_Type'].apply(_broad_type)\n",
    "by_type = (\n",
    "    comp.groupby('broad_type')\n",
    "    .agg(\n",
    "        n_fac        = ('RealFacility_ID', 'nunique'),\n",
    "        mean_anc     = ('anc_pct',  'mean'),\n",
    "        mean_tlo     = ('mean',     'mean'),\n",
    "        mean_resid   = ('residual', 'mean'),\n",
    "        median_resid = ('residual', 'median'),\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "print('\\nBy facility type:')\n",
    "print(by_type.to_string())\n",
    "\n",
    "# ── By year ───────────────────────────────────────────────────────────────────\n",
    "by_year = (\n",
    "    comp.groupby('Year')\n",
    "    .agg(\n",
    "        mean_anc   = ('anc_pct',  'mean'),\n",
    "        mean_tlo   = ('mean',     'mean'),\n",
    "        mean_resid = ('residual', 'mean'),\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "print('\\nBy year:')\n",
    "print(by_year.to_string())"
   ],
   "id": "fa844e68f4681c28",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Residual distribution by facility type and over time ─────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Left: residual boxplot by facility type\n",
    "ax = axes[0]\n",
    "groups_ordered = ['Health Post', 'Health Centre', 'Hospital', 'Other']\n",
    "data_for_box   = [comp.loc[comp['broad_type'] == g, 'residual'].dropna()\n",
    "                  for g in groups_ordered]\n",
    "bp = ax.boxplot(data_for_box, labels=groups_ordered, patch_artist=True,\n",
    "                medianprops=dict(color='black', lw=2))\n",
    "for patch, colour in zip(bp['boxes'],\n",
    "                         ['#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd']):\n",
    "    patch.set_facecolor(colour)\n",
    "    patch.set_alpha(0.6)\n",
    "ax.axhline(0, color='k', lw=1, ls='--', alpha=0.5)\n",
    "ax.set_ylabel('TLO − ANC (percentage points)', fontsize=10)\n",
    "ax.set_title('Residuals by facility type', fontsize=11)\n",
    "ax.grid(True, alpha=0.3, ls=':')\n",
    "\n",
    "# Right: mean residual over time\n",
    "ax = axes[1]\n",
    "mean_resid_year = by_year['mean_resid']\n",
    "ax.bar(mean_resid_year.index, mean_resid_year.values,\n",
    "       color=['#d62728' if v > 0 else '#1f77b4' for v in mean_resid_year.values],\n",
    "       alpha=0.75, edgecolor='white', linewidth=0.5)\n",
    "ax.axhline(0, color='k', lw=1)\n",
    "ax.set_xlabel('Year', fontsize=10)\n",
    "ax.set_ylabel('Mean residual (TLO − ANC, pp)', fontsize=10)\n",
    "ax.set_title('Mean residual over time\\n(red = TLO over-estimates, blue = under-estimates)',\n",
    "             fontsize=11)\n",
    "ax.grid(True, alpha=0.3, ls=':',  axis='y')\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "fig.suptitle('Residual analysis: TLO model vs ANC disruption data',\n",
    "             fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'facility_residual_diagnostics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "9bd319d5cf5404d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Export comparison table ───────────────────────────────────────────────────\n",
    "export_cols = ['RealFacility_ID', 'Year', 'District', 'Facility_Type', 'broad_type',\n",
    "               'mean', 'median', 'p25', 'p75', 'p05', 'p95',\n",
    "               'anc_pct', 'residual', 'abs_residual']\n",
    "export_df = comp[export_cols].round(4)\n",
    "export_path = OUTPUT_DIR / 'facility_level_comparison_table.csv'\n",
    "export_df.to_csv(export_path, index=False)\n",
    "print(f'Saved comparison table → {export_path}')\n",
    "export_df.head()"
   ],
   "id": "c26c3833863b7203",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
